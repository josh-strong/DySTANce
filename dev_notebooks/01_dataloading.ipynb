{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2df65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, re\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Get repository root directory\n",
    "# Try multiple methods to find the repo root\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'data').exists():\n",
    "    REPO_ROOT = cwd\n",
    "elif (cwd.parent / 'data').exists():\n",
    "    REPO_ROOT = cwd.parent\n",
    "else:\n",
    "    # Fallback: assume we're in dev_notebooks and go up one level\n",
    "    REPO_ROOT = cwd.parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce73d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_split_from_filename(fname: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Helper to figure out the split from the filename\n",
    "    \"\"\"\n",
    "    if fname.endswith('test.csv'):\n",
    "        return 'test'\n",
    "    elif fname.endswith('val.csv'):\n",
    "        return 'val'\n",
    "    elif fname.endswith('train.csv'):\n",
    "        return 'train'\n",
    "    else:\n",
    "        import warnings\n",
    "        warnings.warn(f\"Could not infer split from filename: {fname}\", UserWarning)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08361acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2798416/2064284380.py:13: UserWarning: Could not infer split from filename: dada\n",
      "  warnings.warn(f\"Could not infer split from filename: {fname}\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "infer_split_from_filename('dada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb087c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'resnet_mgca_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_mgca_pt_openi_train.csv',\n",
       "  'densenet121_res224_chex': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_chex_train.csv',\n",
       "  'densenet121_res224_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_all_train.csv',\n",
       "  'densenet_medical_mae_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_medical_mae_pt_openi_train.csv',\n",
       "  'densenet_mocov2_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_mocov2_pt_openi_train.csv',\n",
       "  'densenet121_res224_mimic_nb': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_nb_train.csv',\n",
       "  'densenet121_res224_nih': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_nih_train.csv',\n",
       "  'resnet_biovil_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_biovil_pt_openi_train.csv',\n",
       "  'densenet121_res224_mimic_ch': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_ch_train.csv',\n",
       "  'densenet121_res224_rsna': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_rsna_train.csv',\n",
       "  'evax_base_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_base_cxr__pt_openi_train.csv',\n",
       "  'densenet121_res224_pc': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_pc_train.csv',\n",
       "  'evax_small_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_chexpert_pt_openi_train.csv',\n",
       "  'evax_tiny_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_cxr__pt_openi_train.csv',\n",
       "  'evax_small_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_cxr__pt_openi_train.csv',\n",
       "  'evax_tiny_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_chexpert_pt_openi_train.csv',\n",
       "  'resnet50_res512_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet50_res512_all_train.csv',\n",
       "  'resnet_medklip_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_medklip_pt_openi_train.csv'},\n",
       " 'val': {'evax_small_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_cxr__pt_openi_val.csv',\n",
       "  'densenet121_res224_nih': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_nih_val.csv',\n",
       "  'densenet_mocov2_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_mocov2_pt_openi_val.csv',\n",
       "  'evax_tiny_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_cxr__pt_openi_val.csv',\n",
       "  'densenet121_res224_mimic_ch': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_ch_val.csv',\n",
       "  'resnet_medklip_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_medklip_pt_openi_val.csv',\n",
       "  'densenet121_res224_chex': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_chex_val.csv',\n",
       "  'densenet121_res224_mimic_nb': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_nb_val.csv',\n",
       "  'evax_tiny_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_chexpert_pt_openi_val.csv',\n",
       "  'densenet121_res224_rsna': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_rsna_val.csv',\n",
       "  'densenet121_res224_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_all_val.csv',\n",
       "  'evax_base_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_base_cxr__pt_openi_val.csv',\n",
       "  'evax_small_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_chexpert_pt_openi_val.csv',\n",
       "  'densenet121_res224_pc': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_pc_val.csv',\n",
       "  'resnet_mgca_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_mgca_pt_openi_val.csv',\n",
       "  'densenet_medical_mae_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_medical_mae_pt_openi_val.csv',\n",
       "  'resnet50_res512_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet50_res512_all_val.csv',\n",
       "  'resnet_biovil_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_biovil_pt_openi_val.csv'},\n",
       " 'test': {'evax_small_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_chexpert_pt_openi_test.csv',\n",
       "  'densenet121_res224_chex': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_chex_test.csv',\n",
       "  'evax_small_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_small_cxr__pt_openi_test.csv',\n",
       "  'densenet121_res224_nih': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_nih_test.csv',\n",
       "  'resnet_mgca_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_mgca_pt_openi_test.csv',\n",
       "  'resnet50_res512_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet50_res512_all_test.csv',\n",
       "  'densenet_mocov2_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_mocov2_pt_openi_test.csv',\n",
       "  'densenet121_res224_mimic_nb': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_nb_test.csv',\n",
       "  'densenet121_res224_pc': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_pc_test.csv',\n",
       "  'resnet_medklip_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_medklip_pt_openi_test.csv',\n",
       "  'densenet121_res224_mimic_ch': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_mimic_ch_test.csv',\n",
       "  'evax_tiny_chexpert_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_chexpert_pt_openi_test.csv',\n",
       "  'densenet_medical_mae_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet_medical_mae_pt_openi_test.csv',\n",
       "  'densenet121_res224_all': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_all_test.csv',\n",
       "  'densenet121_res224_rsna': '/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_rsna_test.csv',\n",
       "  'resnet_biovil_pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/resnet_biovil_pt_openi_test.csv',\n",
       "  'evax_tiny_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_tiny_cxr__pt_openi_test.csv',\n",
       "  'evax_base_cxr__pt_openi': '/home/kell6630/repos/DySTANce/data/openi/predictions/evax_base_cxr__pt_openi_test.csv'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_prediction_files(pred_dir: str) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Helper to scan prediction files, infer the split from the filename, and return \n",
    "    registry of the form:   \n",
    "        registry[split][tool_name] = csv_path\n",
    "    \"\"\"\n",
    "    registry = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "    for fn in os.listdir(pred_dir):\n",
    "        if not fn.endswith(\".csv\"):\n",
    "            continue\n",
    "        split = infer_split_from_filename(fn)\n",
    "        if split is None:\n",
    "            continue\n",
    "        stem = os.path.splitext(fn)[0]\n",
    "        tool = re.sub(rf\"(_)?{split}(_)?$\", \"\", stem, flags=re.IGNORECASE).strip(\"_\")\n",
    "        registry[split][tool] = os.path.join(pred_dir, fn)\n",
    "    return registry\n",
    "\n",
    "reg = scan_prediction_files(str(REPO_ROOT / 'data' / 'openi' / 'predictions'))\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e25c06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_predictions_csv(\n",
    "    csv_path: str,\n",
    "    label_names: List[str],\n",
    "    id_candidates=(\"id\", \"filename\"),\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Takes in a csv path and a list of label names, and returns a dict of image_id -> [L] float array\n",
    "    This is for the multi-label task, where we treat it as l independent binary classifiers. \n",
    "    Note: Missing or unsupported labels are filled with 0.5!\n",
    "\n",
    "    Returns dict: image_id -> [L] float array\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    with open(csv_path, newline=\"\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        header_lc = [h.lower().strip() for h in header]\n",
    "\n",
    "        id_idx = None\n",
    "        for cand in id_candidates:\n",
    "            if cand in header_lc:\n",
    "                id_idx = header_lc.index(cand)\n",
    "                break\n",
    "        if id_idx is None:\n",
    "            return out\n",
    "\n",
    "        label_idx = []\n",
    "        for l in label_names:\n",
    "            label_idx.append(header_lc.index(l.lower()) if l.lower() in header_lc else None)\n",
    "\n",
    "        for row in reader:\n",
    "            img_id = row[id_idx].replace(\".jpg\", \"\").strip()\n",
    "            vec = []\n",
    "            for j in label_idx:\n",
    "                if j is None:\n",
    "                    vec.append(0.5)\n",
    "                else:\n",
    "                    try:\n",
    "                        vec.append(float(row[j]))\n",
    "                    except Exception:\n",
    "                        vec.append(0.5)\n",
    "            out[img_id] = np.asarray(vec, dtype=np.float32)\n",
    "    return out\n",
    "df = pd.read_csv(REPO_ROOT / 'data' / 'openi' / 'predictions' / 'densenet_mocov2_pt_openi_train.csv')\n",
    "labels = df.drop(columns=['filename']).columns.tolist()\n",
    "out = read_predictions_csv(str(REPO_ROOT / 'data' / 'openi' / 'predictions' / 'densenet_mocov2_pt_openi_train.csv'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "def _fallback_to_tensor(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    if arr.ndim == 2:\n",
    "        arr = np.stack([arr, arr, arr], axis=-1)\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1)\n",
    "\n",
    "class OpenIRoutedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for the OpenI dataset\n",
    "\n",
    "    Returns per-sample:\n",
    "      image        : Tensor[C,H,W]\n",
    "      gt           : Tensor[L]\n",
    "      tool_preds   : Tensor[M, L]\n",
    "      tool_mask    : Tensor[M, L]  (1 = tool valid for task, 0 invalide)\n",
    "      id           : str\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        label_csv: str,\n",
    "        images_dir: str,\n",
    "        predictions_registry: Dict[str, str],\n",
    "        label_names: List[str],\n",
    "        transform=None,\n",
    "        check_files=False,\n",
    "    ):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.label_names = label_names\n",
    "        self.L = len(label_names)\n",
    "\n",
    "        # --- Load labels ---\n",
    "        self.records = []\n",
    "        with open(label_csv, newline=\"\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader)\n",
    "            hmap = {h.strip(): i for i, h in enumerate(header)}\n",
    "            for row in reader:\n",
    "                img_id = row[0].strip()\n",
    "                path = os.path.join(images_dir, f\"{img_id}.jpg\")\n",
    "                if check_files and not os.path.exists(path):\n",
    "                    continue\n",
    "                gt = [float(row[hmap[l]]) for l in label_names]\n",
    "                self.records.append({\n",
    "                    \"id\": img_id,\n",
    "                    \"path\": path,\n",
    "                    \"gt\": torch.tensor(gt, dtype=torch.float32)\n",
    "                })\n",
    "\n",
    "        # --- Load tool predictions ---\n",
    "        self.tool_names = sorted(predictions_registry.keys())\n",
    "        self.M = len(self.tool_names)\n",
    "\n",
    "        self.tool_preds = []\n",
    "        for tool in self.tool_names:\n",
    "            self.tool_preds.append(\n",
    "                read_predictions_csv(predictions_registry[tool], label_names)\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.records[idx]\n",
    "\n",
    "        img = Image.open(rec[\"path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = _fallback_to_tensor(img)\n",
    "\n",
    "        preds = torch.full((self.M, self.L), 0.5)\n",
    "        mask  = torch.zeros((self.M, self.L))\n",
    "\n",
    "        for m, tool_dict in enumerate(self.tool_preds):\n",
    "            if rec[\"id\"] in tool_dict:\n",
    "                p = torch.from_numpy(tool_dict[rec[\"id\"]])\n",
    "                preds[m] = p\n",
    "                mask[m] = (torch.abs(p - 0.5) > 1e-4).float()\n",
    "\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"gt\": rec[\"gt\"],\n",
    "            \"tool_preds\": preds,\n",
    "            \"tool_mask\": mask,\n",
    "            \"id\": rec[\"id\"]\n",
    "        }\n",
    "\n",
    "\n",
    "tr_demo_dataset = OpenIRoutedDataset(\n",
    "    label_csv=str(REPO_ROOT / 'data' / 'openi' / 'labels' / 'Train.csv'),\n",
    "    images_dir=str(REPO_ROOT / 'data' / 'openi' / 'image'),\n",
    "    predictions_registry=reg['train'],\n",
    "    label_names=labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de7a54d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Atelectasis  Consolidation  Infiltration  Pneumothorax  Edema  \\\n",
       "0  2498            0              0             0             0      0   \n",
       "\n",
       "   Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  Cardiomegaly  \\\n",
       "0          0         0         0          0                   0             1   \n",
       "\n",
       "   Nodule  Mass  Hernia  Lung Lesion  Fracture  Lung Opacity  \\\n",
       "0       0     0       0            0         0             0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  \n",
       "0                           0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t = pd.read_csv(\"/home/kell6630/repos/DySTANce/data/openi/labels/Train.csv\")\n",
    "t[t.id == 2498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0216a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"/home/kell6630/repos/DySTANce/data/openi/predictions/densenet121_res224_chex_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc578b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2498.jpg</td>\n",
       "      <td>0.567109</td>\n",
       "      <td>0.513055</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>0.73178</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.525418</td>\n",
       "      <td>0.093608</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.629219</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.257515</td>\n",
       "      <td>0.568898</td>\n",
       "      <td>0.555906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
       "648  2498.jpg     0.567109       0.513055           0.5      0.039836   \n",
       "\n",
       "       Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
       "648  0.73178        0.5       0.5  0.525418   0.093608                 0.5   \n",
       "\n",
       "     Cardiomegaly  Nodule  Mass  Hernia  Lung Lesion  Fracture  Lung Opacity  \\\n",
       "648      0.629219     0.5   0.5     0.5     0.034562  0.257515      0.568898   \n",
       "\n",
       "     Enlarged Cardiomediastinum  \n",
       "648                    0.555906  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.filename == '2498.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1924c607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2498'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_demo_dataset[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df61a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_demo_dataset[0]['tool_mask'][1] # it's > 0.5 when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc32610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "class ContextManager:\n",
    "    \"\"\"\n",
    "    Manages the few-shot context sets used to describe tools in DySTANce.\n",
    "\n",
    "    Key idea (from the paper):\n",
    "    ------------------------\n",
    "    Each tool E is represented only through its behaviour\n",
    "    on a small, task-specific context set:\n",
    "\n",
    "        D_E^t = {(x_b, y_b^t, m_E^t(x_b))}_{b=1}^{B_t}\n",
    "\n",
    "    This class is responsible for:\n",
    "      1) Constructing these context sets in a leakage-free way\n",
    "      2) Ensuring context examples are task- and tool-valid\n",
    "      3) Enforcing a strict separation between:\n",
    "           - data used to DESCRIBE tools (context)\n",
    "           - data used to TRAIN the router (routing set)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: OpenIRoutedDataset,\n",
    "        context_fraction: float = 0.1,\n",
    "        examples_per_tool: int = 32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : OpenIRoutedDataset\n",
    "            Full TRAINING dataset containing images, ground-truth labels,\n",
    "            tool predictions, and tool validity masks.\n",
    "\n",
    "        context_fraction : float\n",
    "            Fraction of the training data reserved EXCLUSIVELY for\n",
    "            tool description (context). These samples are never used\n",
    "            for routing loss computation.\n",
    "\n",
    "        examples_per_tool : int\n",
    "            Number of context examples B_t to sample per (tool, task)\n",
    "            when constructing the ANP summary.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.examples_per_tool = examples_per_tool\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # 1) Split dataset indices into CONTEXT and ROUTING partitions\n",
    "        # ------------------------------------------------------------------\n",
    "        # This enforces the core invariance:\n",
    "        #   \"An image used to describe a tool is never used to train the router.\"\n",
    "        #\n",
    "        # This prevents information leakage and ensures the ANP summaries\n",
    "        # remain exogenous to the routing objective.\n",
    "        # ------------------------------------------------------------------\n",
    "        N = len(dataset)\n",
    "        perm = torch.randperm(N).tolist()  # randomly suffles data indices\n",
    "        split = int(context_fraction * N)  # take first split fraction of random indices as context\n",
    "\n",
    "        self.context_idx = perm[:split]    # used ONLY for tool descriptors\n",
    "        self.routing_idx = perm[split:]    # used ONLY for router training\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # 2) Pre-index valid context examples\n",
    "        # ------------------------------------------------------------------\n",
    "        # We build a lookup table:\n",
    "        #\n",
    "        #   (tool_idx, task_idx) -> [dataset indices]\n",
    "        #\n",
    "        # Only examples where:\n",
    "        #   - the tool actually produced a meaningful prediction\n",
    "        #   - for the specific task (label)\n",
    "        #\n",
    "        # are included.\n",
    "        #\n",
    "        # This is critical because many tools emit \"0.5\" for unsupported\n",
    "        # labels, which must NOT contaminate the context set.\n",
    "        # ------------------------------------------------------------------\n",
    "        self.pool = {}  # maps (tool_idx, task_idx) to list of dataset indices\n",
    "\n",
    "        for i in self.context_idx: # for each context example index\n",
    "            item = dataset[i] # get the context example: dict_keys(['image', 'gt', 'tool_preds', 'tool_mask', 'id'])\n",
    "            mask = item[\"tool_mask\"]  # shape: [num_tools, num_tasks]\n",
    "\n",
    "            # Iterate over all (tool, task) pairs and record \"valid\" contexts (i.e. ones where mask > 0.5)\n",
    "            for t in range(dataset.M): # dataset.M = num tools\n",
    "                for l in range(dataset.L): # dataset.L = num labels\n",
    "                    if mask[t, l] > 0.5: # mask is a float validity indicator in [0,1]; >0.5 means \"tool has signal\"\n",
    "                        # This example is informative for tool t on task l\n",
    "                        self.pool.setdefault((t, l), []).append(i)\n",
    "\n",
    "    def sample_context(self, tool_idx: int, task_idx: int):\n",
    "        \"\"\"\n",
    "        Samples a few-shot context set D_E^t for a specific tool and task.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (images, gt_labels, tool_predictions) or None\n",
    "\n",
    "        images           : Tensor[B, C, H, W]\n",
    "        gt_labels        : Tensor[B]\n",
    "        tool_predictions : Tensor[B]\n",
    "\n",
    "        This tuple corresponds exactly to:\n",
    "            (x_b, y_b^t, m_E^t(x_b))_{b=1}^{B_t}\n",
    "\n",
    "        If no valid context exists for (tool, task), returns None.\n",
    "        This signals that the tool has no observable behavior for this task.\n",
    "        \"\"\"\n",
    "\n",
    "        key = (tool_idx, task_idx)\n",
    "        candidates = self.pool.get(key, [])\n",
    "\n",
    "        # If the tool has never produced a valid prediction for this task,\n",
    "        # we cannot construct a meaningful context descriptor.\n",
    "        if len(candidates) == 0:\n",
    "            return None\n",
    "\n",
    "        # Randomly sample up to B_t context examples (few-shot, exchangeable)\n",
    "        idxs = random.sample(\n",
    "            candidates,\n",
    "            k=min(self.examples_per_tool, len(candidates))\n",
    "        )\n",
    "\n",
    "        imgs, gt, preds = [], [], []\n",
    "        for i in idxs:\n",
    "            item = self.dataset[i]\n",
    "\n",
    "            # Each context triple corresponds to:\n",
    "            #   image x_b\n",
    "            #   ground-truth label y_b^t\n",
    "            #   tool prediction m_E^t(x_b)\n",
    "            imgs.append(item[\"image\"])\n",
    "            gt.append(item[\"gt\"][task_idx])\n",
    "            preds.append(item[\"tool_preds\"][tool_idx, task_idx])\n",
    "\n",
    "        return (\n",
    "            torch.stack(imgs),\n",
    "            torch.stack(gt),\n",
    "            torch.stack(preds),\n",
    "        )\n",
    "\n",
    "    def routing_dataset(self):\n",
    "        \"\"\"\n",
    "        Returns the subset of the dataset used for training the router.\n",
    "\n",
    "        This subset is guaranteed to be disjoint from the context set,\n",
    "        ensuring no leakage between tool description and routing loss.\n",
    "        \"\"\"\n",
    "        return Subset(self.dataset, self.routing_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d18b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_demo_ctx_mgr = ContextManager(tr_demo_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd094be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # batch is list of dicts\n",
    "# batch = next(iter(train_loader))\n",
    "\n",
    "# # sample a task\n",
    "# task_idx = torch.randint(0, L, ()).item()\n",
    "\n",
    "# # slice task-specific view\n",
    "# preds = batch[\"tool_preds\"][:, :, task_idx]    # [B, M]\n",
    "# mask  = batch[\"tool_mask\"][:, :, task_idx]     # [B, M]\n",
    "# gt    = batch[\"gt\"][:, task_idx]                # [B]\n",
    "\n",
    "# # hard mask invalid tools BEFORE softmax\n",
    "# router_logits[mask == 0] = -1e9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71c31682",
   "metadata": {},
   "outputs": [],
   "source": [
    "### examples of data loading\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "PREDICTIONS_DIR = str(REPO_ROOT / 'data' / 'openi' / 'predictions')\n",
    "\n",
    "registry_all = scan_prediction_files(PREDICTIONS_DIR)\n",
    "\n",
    "# Example tool split (train on DenseNet + EVA-X, test on ResNets)\n",
    "train_tools = [t for t in registry_all[\"train\"] if \"resnet\" not in t]\n",
    "test_tools  = [t for t in registry_all[\"train\"] if \"resnet\" in t]\n",
    "\n",
    "train_registry = {t: registry_all[\"train\"][t] for t in train_tools}\n",
    "val_registry   = {t: registry_all[\"val\"][t]   for t in train_tools}\n",
    "test_registry  = {t: registry_all[\"test\"][t]  for t in test_tools}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bd7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4be1c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    \"Atelectasis\", \"Consolidation\", \"Infiltration\", \"Pneumothorax\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Effusion\", \"Pneumonia\",\n",
    "    \"Pleural_Thickening\", \"Cardiomegaly\", \"Nodule\", \"Mass\", \"Hernia\",\n",
    "    \"Lung Lesion\", \"Fracture\", \"Lung Opacity\", \"Enlarged Cardiomediastinum\"\n",
    "]\n",
    "\n",
    "train_dataset_full = OpenIRoutedDataset(\n",
    "    label_csv=str(REPO_ROOT / 'data' / 'openi' / 'labels' / 'Train.csv'),\n",
    "    images_dir=str(REPO_ROOT / 'data' / 'openi' / 'image'),\n",
    "    predictions_registry=train_registry,\n",
    "    label_names=label_names,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "val_dataset = OpenIRoutedDataset(\n",
    "    label_csv=str(REPO_ROOT / 'data' / 'openi' / 'labels' / 'Valid.csv'),\n",
    "    images_dir=str(REPO_ROOT / 'data' / 'openi' / 'image'),\n",
    "    predictions_registry=val_registry,\n",
    "    label_names=label_names,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = OpenIRoutedDataset(\n",
    "    label_csv=str(REPO_ROOT / 'data' / 'openi' / 'labels' / 'Test.csv'),\n",
    "    images_dir=str(REPO_ROOT / 'data' / 'openi' / 'image'),\n",
    "    predictions_registry=test_registry,\n",
    "    label_names=label_names,\n",
    "    transform=transform,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bcef8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_mgr = ContextManager(\n",
    "    dataset=train_dataset_full,\n",
    "    context_fraction=0.1,        # 10% reserved for context\n",
    "    examples_per_tool=32,        # B_t\n",
    ")\n",
    "train_dataset = ctx_mgr.routing_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f13ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72c36ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "num_tasks = len(label_names)\n",
    "num_tools = train_dataset_full.M\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1. Sample a task (label) for this routing step\n",
    "        # -------------------------------------------------\n",
    "        task_idx = random.randint(0, num_tasks - 1)\n",
    "\n",
    "        images = batch[\"image\"]                 # [B, C, H, W]\n",
    "        gt     = batch[\"gt\"][:, task_idx]       # [B]\n",
    "        preds  = batch[\"tool_preds\"][:, :, task_idx]  # [B, M]\n",
    "        mask   = batch[\"tool_mask\"][:, :, task_idx]   # [B, M]\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2. Sample context for each tool (ANP input)\n",
    "        # -------------------------------------------------\n",
    "        context_per_tool = []\n",
    "\n",
    "        for tool_idx in range(num_tools):\n",
    "            ctx = ctx_mgr.sample_context(tool_idx, task_idx)\n",
    "\n",
    "            if ctx is None:\n",
    "                context_per_tool.append(None)\n",
    "            else:\n",
    "                ctx_imgs, ctx_gt, ctx_preds = ctx\n",
    "                context_per_tool.append({\n",
    "                    \"images\": ctx_imgs,      # [B_t, C, H, W]\n",
    "                    \"gt\": ctx_gt,            # [B_t]\n",
    "                    \"preds\": ctx_preds,      # [B_t]\n",
    "                })\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3. Forward pass (router + ANP)\n",
    "        # -------------------------------------------------\n",
    "        # router_logits = router(images, context_per_tool, task_idx)\n",
    "        #\n",
    "        # IMPORTANT:\n",
    "        # Mask invalid tools BEFORE softmax\n",
    "        #\n",
    "        # router_logits[mask == 0] = -1e9\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4. Compute comp-sum loss (task-specific)\n",
    "        # -------------------------------------------------\n",
    "        # loss = comp_sum_loss(router_logits, preds, gt, mask)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "### alternatively we need to average over all tasks (labels) rather than randomly sampling\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "num_tasks = len(label_names)\n",
    "num_tools = train_dataset_full.M\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 1. Sample a task (label) for this routing step\n",
    "        # -------------------------------------------------\n",
    "        task_idx = random.randint(0, num_tasks - 1)\n",
    "\n",
    "        images = batch[\"image\"]                 # [B, C, H, W]\n",
    "        gt     = batch[\"gt\"][:, task_idx]       # [B]\n",
    "        preds  = batch[\"tool_preds\"][:, :, task_idx]  # [B, M]\n",
    "        mask   = batch[\"tool_mask\"][:, :, task_idx]   # [B, M]\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 2. Sample context for each tool (ANP input)\n",
    "        # -------------------------------------------------\n",
    "        context_per_tool = []\n",
    "\n",
    "        for tool_idx in range(num_tools):\n",
    "            ctx = ctx_mgr.sample_context(tool_idx, task_idx)\n",
    "\n",
    "            if ctx is None:\n",
    "                context_per_tool.append(None)\n",
    "            else:\n",
    "                ctx_imgs, ctx_gt, ctx_preds = ctx\n",
    "                context_per_tool.append({\n",
    "                    \"images\": ctx_imgs,      # [B_t, C, H, W]\n",
    "                    \"gt\": ctx_gt,            # [B_t]\n",
    "                    \"preds\": ctx_preds,      # [B_t]\n",
    "                })\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 3. Forward pass (router + ANP)\n",
    "        # -------------------------------------------------\n",
    "        # router_logits = router(images, context_per_tool, task_idx)\n",
    "        #\n",
    "        # IMPORTANT:\n",
    "        # Mask invalid tools BEFORE softmax\n",
    "        #\n",
    "        # router_logits[mask == 0] = -1e9\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 4. Compute comp-sum loss (task-specific)\n",
    "        # -------------------------------------------------\n",
    "        # loss = comp_sum_loss(router_logits, preds, gt, mask)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6556fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "router.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        task_idx = random.randint(0, num_tasks - 1)\n",
    "\n",
    "        images = batch[\"image\"]\n",
    "        gt     = batch[\"gt\"][:, task_idx]\n",
    "        preds  = batch[\"tool_preds\"][:, :, task_idx]\n",
    "        mask   = batch[\"tool_mask\"][:, :, task_idx]\n",
    "\n",
    "        # Sample context exactly as during training\n",
    "        context_per_tool = [\n",
    "            ctx_mgr.sample_context(t, task_idx)\n",
    "            for t in range(num_tools)\n",
    "        ]\n",
    "\n",
    "        # router_logits = router(images, context_per_tool, task_idx)\n",
    "        # router_logits[mask == 0] = -1e9\n",
    "        # evaluate routing decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbe4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eal2d-t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2c90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Get repository root directory\n",
    "# Try multiple methods to find the repo root\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'data').exists():\n",
    "    REPO_ROOT = cwd\n",
    "elif (cwd.parent / 'data').exists():\n",
    "    REPO_ROOT = cwd.parent\n",
    "else:\n",
    "    # Fallback: assume we're in dev_notebooks and go up one level\n",
    "    REPO_ROOT = cwd.parent\n",
    "\n",
    "import imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73f1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Paths\n",
    "# ------------------------------------------------------------\n",
    "DATA_ROOT = REPO_ROOT / \"data\" / \"openi\"\n",
    "LABELS_DIR = DATA_ROOT / \"labels\"\n",
    "IMAGES_DIR = DATA_ROOT / \"image\"\n",
    "PRED_DIR   = DATA_ROOT / \"predictions\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Labels (tasks)\n",
    "# ------------------------------------------------------------\n",
    "label_names = [\n",
    "    \"Atelectasis\", \"Consolidation\", \"Infiltration\", \"Pneumothorax\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Effusion\", \"Pneumonia\",\n",
    "    \"Pleural_Thickening\", \"Cardiomegaly\", \"Nodule\", \"Mass\", \"Hernia\",\n",
    "    \"Lung Lesion\", \"Fracture\", \"Lung Opacity\", \"Enlarged Cardiomediastinum\"\n",
    "]\n",
    "num_tasks = len(label_names)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Tool registry\n",
    "# ------------------------------------------------------------\n",
    "registry_all = imports.scan_prediction_files(str(PRED_DIR))\n",
    "\n",
    "# Example split: train on non-resnet tools\n",
    "train_tools = [t for t in registry_all[\"train\"] if \"resnet\" not in t]\n",
    "\n",
    "train_registry = {t: registry_all[\"train\"][t] for t in train_tools}\n",
    "val_registry   = {t: registry_all[\"val\"][t]   for t in train_tools}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Datasets\n",
    "# ------------------------------------------------------------\n",
    "train_dataset_full = imports.OpenIRoutedDataset(\n",
    "    label_csv=str(LABELS_DIR / \"Train.csv\"),\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    predictions_registry=train_registry,\n",
    "    label_names=label_names,\n",
    "    transform=None,  # assume tensor conversion inside dataset\n",
    ")\n",
    "\n",
    "val_dataset = imports.OpenIRoutedDataset(\n",
    "    label_csv=str(LABELS_DIR / \"Valid.csv\"),\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    predictions_registry=val_registry,\n",
    "    label_names=label_names,\n",
    "    transform=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9c643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_mgr = imports.ContextManager(\n",
    "    dataset=train_dataset_full,\n",
    "    context_fraction=0.1,      # 10% context\n",
    "    examples_per_tool=64,      # B_t\n",
    ")\n",
    "\n",
    "train_dataset = ctx_mgr.routing_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b777e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=25,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a180d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2548</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>870</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1795</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3159</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>3565</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2826</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>494</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1234</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(1.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>94</td>\n",
       "      <td>/home/kell6630/repos/DySTANce/data/openi/image...</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               path  \\\n",
       "0    2548  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "1    1829  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "2     870  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "3    1795  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "4    3159  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "..    ...                                                ...   \n",
       "259  3565  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "260  2826  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "261   494  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "262  1234  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "263    94  /home/kell6630/repos/DySTANce/data/openi/image...   \n",
       "\n",
       "                                                    gt  \n",
       "0    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "1    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "2    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "3    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "4    [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "..                                                 ...  \n",
       "259  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "260  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "261  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "262  [tensor(1.), tensor(0.), tensor(0.), tensor(0....  \n",
       "263  [tensor(0.), tensor(0.), tensor(0.), tensor(0....  \n",
       "\n",
       "[264 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(val_loader.dataset.records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "508d307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_arr = []\n",
    "data_arr = []\n",
    "for i in val_loader.dataset.records:\n",
    "    id_arr.append(i['id'])\n",
    "    data_arr.append(i['gt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbdbdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.DataFrame(torch.stack(data_arr), columns=label_names, index=id_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3042a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Atelectasis  Consolidation  Infiltration  Pneumothorax  Edema  \\\n",
       "2548          0.0            0.0           0.0           0.0    0.0   \n",
       "1829          0.0            0.0           0.0           0.0    0.0   \n",
       "870           0.0            0.0           0.0           0.0    0.0   \n",
       "1795          0.0            0.0           0.0           0.0    0.0   \n",
       "3159          0.0            0.0           0.0           0.0    0.0   \n",
       "...           ...            ...           ...           ...    ...   \n",
       "3565          0.0            0.0           0.0           0.0    0.0   \n",
       "2826          0.0            0.0           0.0           0.0    0.0   \n",
       "494           0.0            0.0           0.0           0.0    0.0   \n",
       "1234          1.0            0.0           0.0           0.0    0.0   \n",
       "94            0.0            0.0           0.0           0.0    0.0   \n",
       "\n",
       "      Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
       "2548        0.0       0.0       1.0        0.0                 0.0   \n",
       "1829        0.0       0.0       1.0        0.0                 0.0   \n",
       "870         0.0       0.0       0.0        0.0                 0.0   \n",
       "1795        0.0       0.0       0.0        0.0                 0.0   \n",
       "3159        0.0       0.0       0.0        0.0                 0.0   \n",
       "...         ...       ...       ...        ...                 ...   \n",
       "3565        0.0       0.0       0.0        0.0                 0.0   \n",
       "2826        0.0       0.0       0.0        0.0                 0.0   \n",
       "494         0.0       0.0       0.0        0.0                 0.0   \n",
       "1234        0.0       0.0       0.0        0.0                 0.0   \n",
       "94          0.0       0.0       0.0        0.0                 0.0   \n",
       "\n",
       "      Cardiomegaly  Nodule  Mass  Hernia  Lung Lesion  Fracture  Lung Opacity  \\\n",
       "2548           0.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "1829           1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "870            1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "1795           1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "3159           1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "...            ...     ...   ...     ...          ...       ...           ...   \n",
       "3565           0.0     0.0   0.0     0.0          0.0       0.0           1.0   \n",
       "2826           0.0     0.0   0.0     0.0          0.0       0.0           1.0   \n",
       "494            0.0     0.0   0.0     0.0          0.0       0.0           1.0   \n",
       "1234           1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "94             1.0     0.0   0.0     0.0          0.0       0.0           0.0   \n",
       "\n",
       "      Enlarged Cardiomediastinum  \n",
       "2548                         0.0  \n",
       "1829                         0.0  \n",
       "870                          0.0  \n",
       "1795                         0.0  \n",
       "3159                         0.0  \n",
       "...                          ...  \n",
       "3565                         0.0  \n",
       "2826                         0.0  \n",
       "494                          0.0  \n",
       "1234                         0.0  \n",
       "94                           1.0  \n",
       "\n",
       "[264 rows x 18 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a6463ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dfs = []\n",
    "tool_metrics = {}\n",
    "for i,k in enumerate(val_loader.dataset.tool_preds):\n",
    "    tool_name = val_dataset.tool_names[i]\n",
    "    pred_df = pd.DataFrame(k).T.rename(columns={j: label_names[j] for j in range(len(label_names))}) > 0.5\n",
    "    tool_acc = (pred_df.loc[gt_df.index].values.flatten() == gt_df.values.flatten()).mean()\n",
    "\n",
    "    label_wise_acc = {}\n",
    "    for label_name in label_names:\n",
    "        label_wise_acc[label_name] = (pred_df.loc[gt_df.index, label_name].values == gt_df[label_name].values).mean()\n",
    "\n",
    "\n",
    "    tool_metrics[tool_name] = {\n",
    "        'pred_df': pred_df,\n",
    "        'tool_acc': tool_acc,\n",
    "        'label_wise_acc': label_wise_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c67d76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for tool_name in tool_metrics.keys():\n",
    "    data.append(tool_metrics[tool_name]['label_wise_acc'].values())\n",
    "label_wise_acc_df = pd.DataFrame(data, columns=label_names, index=tool_metrics.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aafaa3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_all</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.496212</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.617424</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_chex</th>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.700758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780303</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.564394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.428030</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.556818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_mimic_ch</th>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.284091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.284091</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.215909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_mimic_nb</th>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.155303</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.564394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_nih</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.689394</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678030</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_pc</th>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.526515</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.859848</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet121_res224_rsna</th>\n",
       "      <td>0.890152</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>0.746212</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.571970</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet_medical_mae_pt_openi</th>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.617424</td>\n",
       "      <td>0.996212</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>densenet_mocov2_pt_openi</th>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.617424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evax_base_cxr__pt_openi</th>\n",
       "      <td>0.901515</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.996212</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evax_small_chexpert_pt_openi</th>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evax_small_cxr__pt_openi</th>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evax_tiny_chexpert_pt_openi</th>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.928030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928030</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evax_tiny_cxr__pt_openi</th>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Atelectasis  Consolidation  Infiltration  \\\n",
       "densenet121_res224_all            0.579545       0.647727      0.590909   \n",
       "densenet121_res224_chex           0.651515       0.700758      1.000000   \n",
       "densenet121_res224_mimic_ch       0.488636       0.242424      1.000000   \n",
       "densenet121_res224_mimic_nb       0.651515       0.272727      1.000000   \n",
       "densenet121_res224_nih            0.579545       0.473485      0.810606   \n",
       "densenet121_res224_pc             0.507576       0.526515      0.488636   \n",
       "densenet121_res224_rsna           0.890152       0.962121      1.000000   \n",
       "densenet_medical_mae_pt_openi     0.897727       0.962121      0.992424   \n",
       "densenet_mocov2_pt_openi          0.897727       0.962121      1.000000   \n",
       "evax_base_cxr__pt_openi           0.901515       0.962121      0.981061   \n",
       "evax_small_chexpert_pt_openi      0.871212       0.958333      1.000000   \n",
       "evax_small_cxr__pt_openi          0.886364       0.962121      0.984848   \n",
       "evax_tiny_chexpert_pt_openi       0.897727       0.958333      1.000000   \n",
       "evax_tiny_cxr__pt_openi           0.893939       0.962121      1.000000   \n",
       "\n",
       "                               Pneumothorax     Edema  Emphysema  Fibrosis  \\\n",
       "densenet121_res224_all             0.742424  0.878788   0.496212  0.409091   \n",
       "densenet121_res224_chex            0.962121  0.431818   1.000000  1.000000   \n",
       "densenet121_res224_mimic_ch        0.064394  0.284091   1.000000  1.000000   \n",
       "densenet121_res224_mimic_nb        0.253788  0.340909   1.000000  1.000000   \n",
       "densenet121_res224_nih             0.655303  0.916667   0.477273  0.530303   \n",
       "densenet121_res224_pc              0.590909  0.803030   0.776515  0.931818   \n",
       "densenet121_res224_rsna            0.977273  0.984848   1.000000  1.000000   \n",
       "densenet_medical_mae_pt_openi      0.977273  0.984848   1.000000  1.000000   \n",
       "densenet_mocov2_pt_openi           0.977273  0.984848   1.000000  1.000000   \n",
       "evax_base_cxr__pt_openi            0.977273  0.984848   1.000000  1.000000   \n",
       "evax_small_chexpert_pt_openi       0.977273  0.939394   1.000000  1.000000   \n",
       "evax_small_cxr__pt_openi           0.977273  0.984848   1.000000  1.000000   \n",
       "evax_tiny_chexpert_pt_openi        0.977273  0.928030   1.000000  1.000000   \n",
       "evax_tiny_cxr__pt_openi            0.977273  0.984848   1.000000  1.000000   \n",
       "\n",
       "                               Effusion  Pneumonia  Pleural_Thickening  \\\n",
       "densenet121_res224_all         0.806818   0.848485            0.715909   \n",
       "densenet121_res224_chex        0.780303   0.799242            0.984848   \n",
       "densenet121_res224_mimic_ch    0.575758   0.284091            0.984848   \n",
       "densenet121_res224_mimic_nb    0.715909   0.155303            0.984848   \n",
       "densenet121_res224_nih         0.772727   0.689394            0.446970   \n",
       "densenet121_res224_pc          0.803030   0.443182            0.859848   \n",
       "densenet121_res224_rsna        0.912879   0.746212            0.984848   \n",
       "densenet_medical_mae_pt_openi  0.950758   0.984848            0.984848   \n",
       "densenet_mocov2_pt_openi       0.950758   0.984848            0.984848   \n",
       "evax_base_cxr__pt_openi        0.935606   0.984848            0.984848   \n",
       "evax_small_chexpert_pt_openi   0.924242   0.984848            0.984848   \n",
       "evax_small_cxr__pt_openi       0.946970   0.984848            0.984848   \n",
       "evax_tiny_chexpert_pt_openi    0.928030   0.984848            0.984848   \n",
       "evax_tiny_cxr__pt_openi        0.939394   0.984848            0.984848   \n",
       "\n",
       "                               Cardiomegaly    Nodule      Mass    Hernia  \\\n",
       "densenet121_res224_all             0.655303  0.439394  0.537879  0.939394   \n",
       "densenet121_res224_chex            0.564394  1.000000  1.000000  1.000000   \n",
       "densenet121_res224_mimic_ch        0.462121  1.000000  1.000000  1.000000   \n",
       "densenet121_res224_mimic_nb        0.537879  1.000000  1.000000  1.000000   \n",
       "densenet121_res224_nih             0.659091  0.750000  0.678030  0.556818   \n",
       "densenet121_res224_pc              0.681818  0.556818  0.666667  0.875000   \n",
       "densenet121_res224_rsna            0.606061  1.000000  1.000000  1.000000   \n",
       "densenet_medical_mae_pt_openi      0.617424  0.996212  0.984848  1.000000   \n",
       "densenet_mocov2_pt_openi           0.617424  1.000000  0.988636  1.000000   \n",
       "evax_base_cxr__pt_openi            0.628788  0.992424  0.977273  0.996212   \n",
       "evax_small_chexpert_pt_openi       0.636364  1.000000  1.000000  1.000000   \n",
       "evax_small_cxr__pt_openi           0.625000  0.992424  0.981061  1.000000   \n",
       "evax_tiny_chexpert_pt_openi        0.643939  1.000000  1.000000  1.000000   \n",
       "evax_tiny_cxr__pt_openi            0.621212  0.992424  0.988636  1.000000   \n",
       "\n",
       "                               Lung Lesion  Fracture  Lung Opacity  \\\n",
       "densenet121_res224_all            0.863636  0.617424      0.666667   \n",
       "densenet121_res224_chex           0.776515  0.428030      0.590909   \n",
       "densenet121_res224_mimic_ch       0.242424  0.291667      0.507576   \n",
       "densenet121_res224_mimic_nb       0.231061  0.534091      0.522727   \n",
       "densenet121_res224_nih            0.909091  0.920455      0.560606   \n",
       "densenet121_res224_pc             0.909091  0.515152      0.560606   \n",
       "densenet121_res224_rsna           0.909091  0.920455      0.571970   \n",
       "densenet_medical_mae_pt_openi     0.909091  0.920455      0.560606   \n",
       "densenet_mocov2_pt_openi          0.909091  0.920455      0.560606   \n",
       "evax_base_cxr__pt_openi           0.909091  0.920455      0.560606   \n",
       "evax_small_chexpert_pt_openi      0.909091  0.920455      0.560606   \n",
       "evax_small_cxr__pt_openi          0.909091  0.920455      0.560606   \n",
       "evax_tiny_chexpert_pt_openi       0.909091  0.920455      0.560606   \n",
       "evax_tiny_cxr__pt_openi           0.909091  0.920455      0.560606   \n",
       "\n",
       "                               Enlarged Cardiomediastinum  \n",
       "densenet121_res224_all                           0.734848  \n",
       "densenet121_res224_chex                          0.556818  \n",
       "densenet121_res224_mimic_ch                      0.215909  \n",
       "densenet121_res224_mimic_nb                      0.564394  \n",
       "densenet121_res224_nih                           0.886364  \n",
       "densenet121_res224_pc                            0.886364  \n",
       "densenet121_res224_rsna                          0.886364  \n",
       "densenet_medical_mae_pt_openi                    0.886364  \n",
       "densenet_mocov2_pt_openi                         0.886364  \n",
       "evax_base_cxr__pt_openi                          0.886364  \n",
       "evax_small_chexpert_pt_openi                     0.886364  \n",
       "evax_small_cxr__pt_openi                         0.886364  \n",
       "evax_tiny_chexpert_pt_openi                      0.886364  \n",
       "evax_tiny_cxr__pt_openi                          0.886364  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_wise_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dcde5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imports.DySTANceRouter(\n",
    "    num_tasks=num_tasks,\n",
    "    vocab_size=1000,   # dummy vocab size for now\n",
    "    hidden_dim=256,\n",
    ").to(device)\n",
    "\n",
    "# criterion = imports.DySTANceLoss(\n",
    "#     surrogate_type=\"logistic\",\n",
    "#     lambda_entropy=0.05,\n",
    "# )\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "\n",
    "def build_context_tensors(ctx_mgr, task_idx, device):\n",
    "    \"\"\"\n",
    "    Builds task-conditional context tensors for all tools.\n",
    "\n",
    "    Returns:\n",
    "        ctx_img_feat : [M, C, Dx] on `device`\n",
    "        ctx_gt       : [M, C]     on `device`\n",
    "        ctx_pred     : [M, C]     on `device`\n",
    "    \"\"\"\n",
    "    ctx_img_feats = []\n",
    "    ctx_gts = []\n",
    "    ctx_preds = []\n",
    "\n",
    "    M = ctx_mgr.dataset.M # number of tools\n",
    "    C = ctx_mgr.examples_per_tool # number of examples\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        ctx = ctx_mgr.sample_context(tool_idx, task_idx)\n",
    "\n",
    "        if ctx is None:\n",
    "            # No valid context for this tool-task pair\n",
    "            ctx_img_feats.append(\n",
    "                torch.zeros(C, model.img_dim, device=device)\n",
    "            )\n",
    "            ctx_gts.append(\n",
    "                torch.zeros(C, device=device)\n",
    "            )\n",
    "            ctx_preds.append(\n",
    "                torch.zeros(C, device=device)\n",
    "            )\n",
    "        else:\n",
    "            imgs, gt, preds = ctx\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            gt = gt.to(device)\n",
    "            preds = preds.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                feats = model.extract_img_feat(imgs)  # [C, Dx]\n",
    "\n",
    "            ctx_img_feats.append(feats)\n",
    "            ctx_gts.append(gt)\n",
    "            ctx_preds.append(preds)\n",
    "\n",
    "    return (\n",
    "        torch.stack(ctx_img_feats, dim=0),  # [M, C, Dx]\n",
    "        torch.stack(ctx_gts, dim=0),        # [M, C]\n",
    "        torch.stack(ctx_preds, dim=0),      # [M, C]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2c15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, ctx_mgr, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        images = batch[\"image\"].to(device)        # [B, 3, H, W]\n",
    "        gt_all = batch[\"gt\"].to(device)           # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)  # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)    # [B, M, L]\n",
    "\n",
    "        B = images.size(0)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 1) Sample a task uniformly\n",
    "        # ------------------------------------------------------------\n",
    "        task_idx = random.randint(0, num_tasks - 1)\n",
    "        task_ids = torch.full((B,), task_idx, device=device, dtype=torch.long)\n",
    "\n",
    "        # Task-conditional slices\n",
    "        gt = gt_all[:, task_idx]                 # [B]\n",
    "        tool_preds = preds_all[:, :, task_idx]   # [B, M]\n",
    "        tool_mask  = mask_all[:, :, task_idx]    # [B, M]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 2) Build context for this task\n",
    "        # ------------------------------------------------------------\n",
    "        ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(\n",
    "            ctx_mgr, task_idx, device\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 3) Forward pass\n",
    "        # ------------------------------------------------------------\n",
    "        scores = model(\n",
    "            images=images,\n",
    "            text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text\n",
    "            task_idx=task_ids,\n",
    "            tool_preds=tool_preds,\n",
    "            ctx_img_feat=ctx_img_feat,\n",
    "            ctx_gt=ctx_gt,\n",
    "            ctx_pred=ctx_pred,\n",
    "            tool_mask=tool_mask,\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 4) Compute costs (classification task)\n",
    "        # c_E = 1 - confidence on true label\n",
    "        # ------------------------------------------------------------\n",
    "        tool_costs = 1.0 - tool_preds  # [B, M]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # 5) Loss + backward\n",
    "        # ------------------------------------------------------------\n",
    "        loss, logs = criterion(scores, tool_costs, tool_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    return total_loss / max(1, total_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56bf52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def train_one_epoch_all_tasks(model, loader, ctx_mgr, optimizer, criterion, task_weights: Optional[torch.Tensor] = None):\n",
    "    \"\"\"\n",
    "    Train one epoch but evaluate the comp-sum loss for every task in each batch,\n",
    "    then average the losses across tasks and take a single optimization step.\n",
    "\n",
    "    Args:\n",
    "        model: the DySTANce model (model.train() will be called)\n",
    "        loader: DataLoader yielding batches with keys:\n",
    "                \"image\" -> [B,3,H,W],\n",
    "                \"gt\"    -> [B,L],\n",
    "                \"tool_preds\" -> [B, M, L],\n",
    "                \"tool_mask\"  -> [B, M, L]\n",
    "        ctx_mgr: ContextManager used to build ANP contexts (build_context_tensors wrapper)\n",
    "        optimizer: optimizer to step\n",
    "        criterion: DySTANceLoss instance (callable -> (loss, logs))\n",
    "        task_weights: optional Tensor [L] to weight tasks (on CPU or device). If None, uniform.\n",
    "    Returns:\n",
    "        avg_loss_per_batch: scalar float\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Optional task weights (defaults to uniform)\n",
    "    if task_weights is None:\n",
    "        task_weights = torch.ones((num_tasks,), dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        # move to device\n",
    "        task_weights = task_weights.to(device).float()\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        images = batch[\"image\"].to(device)                 # [B, 3, H, W]\n",
    "        gt_all = batch[\"gt\"].to(device)                   # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)        # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)          # [B, M, L]\n",
    "\n",
    "        B = images.size(0)\n",
    "\n",
    "        # Accumulate loss over tasks for this minibatch\n",
    "        loss_sum_tasks = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        # Loop over tasks (labels)\n",
    "        for t in range(num_tasks):\n",
    "            # ---------------------------\n",
    "            # 1) Task slices\n",
    "            # ---------------------------\n",
    "            task_ids = torch.full((B,), t, device=device, dtype=torch.long)\n",
    "            gt = gt_all[:, t]                     # [B]\n",
    "            tool_preds = preds_all[:, :, t]       # [B, M]\n",
    "            tool_mask  = mask_all[:, :, t]        # [B, M]\n",
    "\n",
    "            # Quick check: if *none* of the tools are valid for this task across the batch,\n",
    "            # then there's nothing to route to — skip or handle specially.\n",
    "            # Here we skip such tasks (no contribution to loss) to avoid degenerate behavior.\n",
    "            if tool_mask.sum() == 0:\n",
    "                # skip this task (no valid tools in the panel for any sample)\n",
    "                continue\n",
    "\n",
    "            # ---------------------------\n",
    "            # 2) Build context tensors for this task\n",
    "            #    (build_context_tensors must return CPU tensors; move to device)\n",
    "            # ---------------------------\n",
    "            ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, device=device)\n",
    "\n",
    "            # Ensure returned tensors are moved to the correct device\n",
    "            # (some implementations already return on device; this is idempotent)\n",
    "            if ctx_img_feat is not None:\n",
    "                ctx_img_feat = ctx_img_feat.to(device)\n",
    "                ctx_gt = ctx_gt.to(device)\n",
    "                ctx_pred = ctx_pred.to(device)\n",
    "            else:\n",
    "                # If NO context exists for this task (all tools unseen for this task),\n",
    "                # we should still provide reasonable placeholders to the model.\n",
    "                # We set empty (zero) contexts with zero sizes: M=number of tools, C=0 -> handle in ANP.\n",
    "                # For simplicity, create zero-sized contexts of expected shapes:\n",
    "                # We assume ctx_mgr and model expect shape [M, C, Dx] etc. If your ANP\n",
    "                # has special handling for B_t=0, ensure it accepts those tensors.\n",
    "                M = preds_all.shape[1]\n",
    "                Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "                # make shapes consistent with your ANP — here we create C=0 context\n",
    "                ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "                ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "                ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "\n",
    "            # ---------------------------\n",
    "            # 3) Forward pass for this task\n",
    "            # ---------------------------\n",
    "            scores = model(\n",
    "                images=images,\n",
    "                text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text or real tokens\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_preds,\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask,\n",
    "            )  # [B, M]\n",
    "\n",
    "            # ---------------------------\n",
    "            # 4) Build costs (task-specific)\n",
    "            #    For classification: c_E = 1 - confidence on true label (soft proxy)\n",
    "            # ---------------------------\n",
    "            tool_costs = 1.0 - tool_preds  # [B, M]\n",
    "\n",
    "            # ---------------------------\n",
    "            # 5) Compute loss for this task\n",
    "            # ---------------------------\n",
    "            loss_t, logs = criterion(scores, tool_costs, tool_mask)  # scalar loss_t tensor + logs dict\n",
    "\n",
    "            # Weight the task (uniform by default)\n",
    "            w_t = float(task_weights[t].item())\n",
    "            loss_sum_tasks = loss_sum_tasks + (w_t * loss_t)\n",
    "            weight_sum += w_t\n",
    "\n",
    "        # If no tasks contributed (extremely unlikely), skip update\n",
    "        if weight_sum == 0:\n",
    "            continue\n",
    "\n",
    "        # Average across tasks\n",
    "        loss_batch = loss_sum_tasks / weight_sum\n",
    "\n",
    "        # Backprop and step once per minibatch\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss_batch.detach().cpu().item())\n",
    "        total_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_batches)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f400aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, ctx_mgr):\n",
    "    \"\"\"\n",
    "    Evaluates DySTANce router on:\n",
    "      - average regret\n",
    "      - per-task accuracy (binary)\n",
    "\n",
    "    Task is sampled per batch (same as training).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_regret = 0.0\n",
    "    total_samples = 0\n",
    "    correct_total = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Validation\"):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        gt_all = batch[\"gt\"].to(device)                # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)     # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)       # [B, M, L]\n",
    "\n",
    "        B = images.size(0)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Sample a task (same protocol as training)\n",
    "        # ------------------------------------------------------------\n",
    "        task_idx = random.randint(0, num_tasks - 1)\n",
    "        task_ids = torch.full((B,), task_idx, device=device, dtype=torch.long)\n",
    "\n",
    "        gt = gt_all[:, task_idx]                       # [B]\n",
    "        tool_preds = preds_all[:, :, task_idx]         # [B, M]\n",
    "        tool_mask  = mask_all[:, :, task_idx]          # [B, M]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Build task-conditional context\n",
    "        # ------------------------------------------------------------\n",
    "        ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(\n",
    "            ctx_mgr, task_idx, device\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Forward pass\n",
    "        # ------------------------------------------------------------\n",
    "        scores = model(\n",
    "            images,\n",
    "            torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text\n",
    "            task_ids,\n",
    "            tool_preds,\n",
    "            ctx_img_feat,\n",
    "            ctx_gt,\n",
    "            ctx_pred,\n",
    "            tool_mask,\n",
    "        )\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Routing decision\n",
    "        # ------------------------------------------------------------\n",
    "        chosen = scores.argmax(dim=1)  # [B]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Regret computation\n",
    "        # ------------------------------------------------------------\n",
    "        costs = 1.0 - tool_preds       # [B, M]\n",
    "\n",
    "        chosen_cost = costs[torch.arange(B), chosen]\n",
    "        oracle_cost = costs.masked_fill(tool_mask == 0, 1e9).min(dim=1).values\n",
    "\n",
    "        total_regret += (chosen_cost - oracle_cost).sum().item()\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Accuracy computation (binary)\n",
    "        # ------------------------------------------------------------\n",
    "        chosen_preds = tool_preds[torch.arange(B), chosen]  # [B]\n",
    "        chosen_labels = (chosen_preds >= 0.5).long()\n",
    "\n",
    "        correct_total += (chosen_labels == gt).sum().item()\n",
    "        total_samples += B\n",
    "\n",
    "    avg_regret = total_regret / max(1, total_samples)\n",
    "    accuracy = correct_total / max(1, total_samples)\n",
    "\n",
    "    return {\n",
    "        \"avg_regret\": avg_regret,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"num_samples\": total_samples,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002f7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_all_tasks(model, loader, ctx_mgr):\n",
    "    \"\"\"\n",
    "    Evaluate DySTANce over EVERY task per batch (no random single-task sampling).\n",
    "\n",
    "    Returns a dict with:\n",
    "      - avg_regret      : average regret across all considered (sample,task) pairs\n",
    "      - accuracy        : overall accuracy (router chosen tool vs GT)\n",
    "      - per_task_acc    : list of per-task accuracies\n",
    "      - random_acc      : random-router baseline accuracy\n",
    "      - upper_bound_acc : oracle upper-ceiling accuracy\n",
    "      - num_pairs       : number of considered (sample,task) pairs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Accumulators\n",
    "    total_regret = 0.0\n",
    "    total_correct = 0\n",
    "    total_pairs = 0\n",
    "\n",
    "    # Per-task accumulators\n",
    "    per_task_correct = [0 for _ in range(num_tasks)]\n",
    "    per_task_pairs = [0 for _ in range(num_tasks)]\n",
    "\n",
    "    # Baselines\n",
    "    random_correct = 0\n",
    "    upper_correct = 0\n",
    "\n",
    "    # Cache contexts per task to avoid repeated builds\n",
    "    ctx_cache = {}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Validation\"):\n",
    "        images = batch[\"image\"].to(device)            # [B, C, H, W]\n",
    "        gt_all  = batch[\"gt\"].to(device)             # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "        mask_all  = batch[\"tool_mask\"].to(device)    # [B, M, L]\n",
    "\n",
    "        B = images.shape[0]\n",
    "\n",
    "        # For each task, evaluate all samples in batch (but skip samples with no valid tool)\n",
    "        for t in range(num_tasks):\n",
    "            # Task slices\n",
    "            gt = gt_all[:, t]                       # [B]\n",
    "            tool_preds = preds_all[:, :, t]         # [B, M]\n",
    "            tool_mask  = mask_all[:, :, t]          # [B, M] {0,1}\n",
    "\n",
    "            # Determine which samples in this batch have at least one valid tool\n",
    "            valid_tool_counts = tool_mask.sum(dim=1)        # [B]\n",
    "            valid_samples_mask = (valid_tool_counts > 0)   # [B] bool\n",
    "\n",
    "            if valid_samples_mask.sum().item() == 0:\n",
    "                # no sample in this batch has any valid tool for this task -> skip\n",
    "                continue\n",
    "\n",
    "            # Build / fetch cached context for task t (move to device)\n",
    "            if t in ctx_cache:\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = ctx_cache[t]\n",
    "            else:\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, device=device)\n",
    "                # move to device (build_context_tensors may return CPU tensors)\n",
    "                if ctx_img_feat is not None:\n",
    "                    ctx_img_feat = ctx_img_feat.to(device)\n",
    "                    ctx_gt = ctx_gt.to(device)\n",
    "                    ctx_pred = ctx_pred.to(device)\n",
    "                else:\n",
    "                    # Create zero-sized contexts if none exist (ANP should handle B_t=0)\n",
    "                    M = preds_all.shape[1]\n",
    "                    Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "                    ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "                    ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "                    ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "\n",
    "                ctx_cache[t] = (ctx_img_feat, ctx_gt, ctx_pred)\n",
    "\n",
    "            # Build task ids for the batch\n",
    "            task_ids = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "\n",
    "            # Forward pass (model expected to handle masking internally)\n",
    "            scores = model(\n",
    "                images=images,\n",
    "                text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text (or real tokens if available)\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_preds,\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask,\n",
    "            )  # [B, M]\n",
    "\n",
    "            # Ensure invalid tools have very low score (safety)\n",
    "            scores = scores.masked_fill(tool_mask == 0, -1e9)\n",
    "\n",
    "            # Choose best tool per sample\n",
    "            chosen = scores.argmax(dim=1)  # [B] (may point to invalid tool if all -inf; but we filtered such samples)\n",
    "\n",
    "            # Consider only samples with at least one valid tool\n",
    "            idxs = torch.nonzero(valid_samples_mask, as_tuple=False).squeeze(1)  # [B_valid]\n",
    "            if idxs.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            # Subset arrays to valid samples\n",
    "            chosen_v = chosen[idxs]                          # [B_valid]\n",
    "            gt_v = gt[idxs]                                 # [B_valid]\n",
    "            preds_v = tool_preds[idxs]                      # [B_valid, M]\n",
    "            mask_v  = tool_mask[idxs]                       # [B_valid, M]\n",
    "\n",
    "            # Costs: c = 1 - confidence (soft proxy)\n",
    "            costs_v = 1.0 - preds_v                         # [B_valid, M]\n",
    "\n",
    "            # Chosen cost and oracle cost\n",
    "            chosen_cost = costs_v[torch.arange(idxs.numel(), device=device), chosen_v]  # [B_valid]\n",
    "\n",
    "            # Oracle: min cost among valid tools\n",
    "            inf_mask = (~(mask_v.bool())).float() * 1e9\n",
    "            costs_for_oracle = costs_v + inf_mask\n",
    "            oracle_cost = costs_for_oracle.min(dim=1).values  # [B_valid]\n",
    "\n",
    "            total_regret += (chosen_cost - oracle_cost).sum().item()\n",
    "\n",
    "            # Accuracy: interpret chosen tool's prediction as binary label (>=0.5)\n",
    "            chosen_pred_probs = preds_v[torch.arange(idxs.numel(), device=device), chosen_v]  # [B_valid]\n",
    "            chosen_labels = (chosen_pred_probs >= 0.5).long()\n",
    "            correct = (chosen_labels == gt_v).sum().item()\n",
    "            total_correct += int(correct)\n",
    "            total_pairs += int(idxs.numel())\n",
    "\n",
    "            # Per-task accounting\n",
    "            per_task_correct[t] += int(correct)\n",
    "            per_task_pairs[t] += int(idxs.numel())\n",
    "\n",
    "            # --- Baselines for these valid samples --------------------------------\n",
    "            # Random-router baseline: choose uniformly among valid tools for each sample\n",
    "            # We implement this in vectorized-ish manner:\n",
    "            Bv, M = preds_v.shape\n",
    "            # Create list of valid tool indices per sample\n",
    "            # We'll loop here across Bv (Bv is smallish per batch)\n",
    "            for i in range(Bv):\n",
    "                valid_indices = torch.nonzero(mask_v[i].bool(), as_tuple=False).squeeze(1)\n",
    "                if valid_indices.numel() == 0:\n",
    "                    # Shouldn't happen due to earlier filtering\n",
    "                    continue\n",
    "                # Random pick\n",
    "                rnd_idx = int(valid_indices[torch.randint(0, valid_indices.numel(), (1,)).item()].item())\n",
    "                rnd_prob = preds_v[i, rnd_idx].item()\n",
    "                rnd_label = 1 if rnd_prob >= 0.5 else 0\n",
    "                if rnd_label == int(gt_v[i].item()):\n",
    "                    random_correct += 1\n",
    "\n",
    "                # Upper-ceiling: any valid tool predicts correctly?\n",
    "                # If any valid tool's binary prediction equals gt, count as correct\n",
    "                # (treat prob>=0.5 as predicting label=1)\n",
    "                valid_probs = preds_v[i, valid_indices]\n",
    "                valid_preds_bin = (valid_probs >= 0.5).long()\n",
    "                if (valid_preds_bin == int(gt_v[i].item())).any():\n",
    "                    upper_correct += 1\n",
    "            # ----------------------------------------------------------------------\n",
    "\n",
    "    # After all batches\n",
    "    avg_regret = total_regret / max(1, total_pairs)\n",
    "    accuracy = total_correct / max(1, total_pairs)\n",
    "    per_task_acc = [ (per_task_correct[t] / per_task_pairs[t]) if per_task_pairs[t] > 0 else None\n",
    "                     for t in range(num_tasks) ]\n",
    "\n",
    "    random_acc = random_correct / max(1, total_pairs)\n",
    "    upper_acc  = upper_correct / max(1, total_pairs)\n",
    "\n",
    "    return {\n",
    "        \"avg_regret\": avg_regret,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"per_task_acc\": per_task_acc,\n",
    "        \"random_acc\": random_acc,\n",
    "        \"upper_acc\": upper_acc,\n",
    "        \"num_pairs\": total_pairs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07811cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 0: 100%|██████████| 11/11 [00:00<00:00, 57.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 0): 0.9924\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 1: 100%|██████████| 11/11 [00:00<00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 1): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 2: 100%|██████████| 11/11 [00:00<00:00, 64.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 2): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 3: 100%|██████████| 11/11 [00:00<00:00, 62.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 3): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 4: 100%|██████████| 11/11 [00:00<00:00, 73.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 4): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 5: 100%|██████████| 11/11 [00:00<00:00, 59.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 5): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 6: 100%|██████████| 11/11 [00:00<00:00, 61.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 6): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 7: 100%|██████████| 11/11 [00:00<00:00, 60.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 7): 0.9924\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 8: 100%|██████████| 11/11 [00:00<00:00, 70.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 8): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 9: 100%|██████████| 11/11 [00:00<00:00, 73.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 9): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 10: 100%|██████████| 11/11 [00:00<00:00, 64.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 10): 0.9432\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 11: 100%|██████████| 11/11 [00:00<00:00, 68.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 11): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 12: 100%|██████████| 11/11 [00:00<00:00, 63.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 12): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 13: 100%|██████████| 11/11 [00:00<00:00, 70.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 13): 1.0000\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 14: 100%|██████████| 11/11 [00:00<00:00, 64.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 14): 0.9432\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 15: 100%|██████████| 11/11 [00:00<00:00, 65.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 15): 0.8598\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 16: 100%|██████████| 11/11 [00:00<00:00, 74.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 16): 0.9205\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ceiling task 17: 100%|██████████| 11/11 [00:00<00:00, 67.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper-ceiling accuracy (task 17): 0.8750\n",
      "{'total_samples': 264, 'samples_with_any_valid_tool': 264, 'fraction_with_any_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_upper_ceiling_accuracy(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the upper-ceiling accuracy for a single task.\n",
    "\n",
    "    Upper-ceiling = fraction of samples for which at least one\n",
    "    valid tool predicts the correct label.\n",
    "\n",
    "    Args:\n",
    "        dataloader : DataLoader yielding OpenIRoutedDataset batches\n",
    "        task_idx   : int, which task (label) to evaluate\n",
    "        device     : torch device\n",
    "\n",
    "    Returns:\n",
    "        ceiling_acc : float in [0,1]\n",
    "        stats       : dict with additional diagnostics\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    count_ceiling = 0\n",
    "    count_any_valid = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Ceiling task {task_idx}\"):\n",
    "        gt = batch[\"gt\"][:, task_idx].to(device)            # [B]\n",
    "        preds = batch[\"tool_preds\"][:, :, task_idx].to(device)  # [B, M]\n",
    "        mask = batch[\"tool_mask\"][:, :, task_idx].to(device)    # [B, M]\n",
    "\n",
    "        B, M = preds.shape\n",
    "\n",
    "        # Predicted labels per tool (binary classification)\n",
    "        pred_labels = (preds >= 0.5).long()  # [B, M]\n",
    "\n",
    "        # Ground truth expanded\n",
    "        gt_exp = gt.unsqueeze(1).expand(-1, M)  # [B, M]\n",
    "\n",
    "        # Correct predictions per tool\n",
    "        correct = (pred_labels == gt_exp) & (mask.bool())  # [B, M]\n",
    "\n",
    "        # For each sample: does ANY tool get it right?\n",
    "        any_correct = correct.any(dim=1)  # [B]\n",
    "\n",
    "        # For sanity: does sample have ANY valid tool?\n",
    "        any_valid = mask.any(dim=1)       # [B]\n",
    "\n",
    "        count_ceiling += any_correct.sum().item()\n",
    "        count_any_valid += any_valid.sum().item()\n",
    "        total += B\n",
    "\n",
    "    ceiling_acc = count_ceiling / max(1, total)\n",
    "\n",
    "    stats = {\n",
    "        \"total_samples\": total,\n",
    "        \"samples_with_any_valid_tool\": count_any_valid,\n",
    "        \"fraction_with_any_valid_tool\": count_any_valid / max(1, total),\n",
    "    }\n",
    "\n",
    "    return ceiling_acc, stats\n",
    "\n",
    "for task_idx in range(num_tasks):\n",
    "    ceiling_acc, stats = compute_upper_ceiling_accuracy(\n",
    "        val_loader,\n",
    "        task_idx=task_idx,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    print(f\"Upper-ceiling accuracy (task {task_idx}): {ceiling_acc:.4f}\")\n",
    "    print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a26392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 0: 100%|██████████| 11/11 [00:00<00:00, 60.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 0): 0.7652\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 1: 100%|██████████| 11/11 [00:00<00:00, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 1): 0.7462\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 2: 100%|██████████| 11/11 [00:00<00:00, 65.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 2): 0.8409\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 3: 100%|██████████| 11/11 [00:00<00:00, 70.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 3): 0.7197\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 4: 100%|██████████| 11/11 [00:00<00:00, 69.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 4): 0.8144\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 5: 100%|██████████| 11/11 [00:00<00:00, 60.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 5): 0.8182\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 6: 100%|██████████| 11/11 [00:00<00:00, 59.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 6): 0.8447\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 7: 100%|██████████| 11/11 [00:00<00:00, 59.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 7): 0.8485\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 8: 100%|██████████| 11/11 [00:00<00:00, 67.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 8): 0.7424\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 9: 100%|██████████| 11/11 [00:00<00:00, 61.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 9): 0.8485\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 10: 100%|██████████| 11/11 [00:00<00:00, 64.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 10): 0.6136\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 11: 100%|██████████| 11/11 [00:00<00:00, 64.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 11): 0.8106\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 12: 100%|██████████| 11/11 [00:00<00:00, 68.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 12): 0.8447\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 13: 100%|██████████| 11/11 [00:00<00:00, 64.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 13): 0.8939\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 14: 100%|██████████| 11/11 [00:00<00:00, 65.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 14): 0.5152\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 15: 100%|██████████| 11/11 [00:00<00:00, 60.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 15): 0.4470\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 16: 100%|██████████| 11/11 [00:00<00:00, 63.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 16): 0.5758\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router task 17: 100%|██████████| 11/11 [00:00<00:00, 69.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random router accuracy (task 17): 0.4621\n",
      "{'total_samples': 264, 'samples_with_valid_tool': 264, 'fraction_with_valid_tool': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_random_router_accuracy(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "    seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes accuracy of a random router for a single task.\n",
    "\n",
    "    For each sample:\n",
    "      - uniformly sample one VALID tool\n",
    "      - use its prediction as the output\n",
    "\n",
    "    Args:\n",
    "        dataloader : DataLoader yielding OpenIRoutedDataset batches\n",
    "        task_idx   : int, which task (label) to evaluate\n",
    "        device     : torch device\n",
    "        seed       : random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        rand_acc : float in [0,1]\n",
    "        stats    : dict\n",
    "    \"\"\"\n",
    "    rng = torch.Generator(device=device)\n",
    "    rng.manual_seed(seed)\n",
    "\n",
    "    total = 0\n",
    "    correct_total = 0\n",
    "    samples_with_valid = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Random router task {task_idx}\"):\n",
    "        gt = batch[\"gt\"][:, task_idx].to(device)             # [B]\n",
    "        preds = batch[\"tool_preds\"][:, :, task_idx].to(device)  # [B, M]\n",
    "        mask = batch[\"tool_mask\"][:, :, task_idx].to(device)    # [B, M]\n",
    "\n",
    "        B, M = preds.shape\n",
    "\n",
    "        for i in range(B):\n",
    "            valid_tools = torch.nonzero(mask[i], as_tuple=False).squeeze(-1)\n",
    "\n",
    "            if valid_tools.numel() == 0:\n",
    "                # No valid tool: cannot predict (count as incorrect)\n",
    "                total += 1\n",
    "                continue\n",
    "\n",
    "            samples_with_valid += 1\n",
    "\n",
    "            # Uniform random choice among valid tools\n",
    "            j = valid_tools[\n",
    "                torch.randint(\n",
    "                    low=0,\n",
    "                    high=valid_tools.numel(),\n",
    "                    size=(1,),\n",
    "                    generator=rng,\n",
    "                    device=device,\n",
    "                ).item()\n",
    "            ]\n",
    "\n",
    "            # Binary prediction\n",
    "            pred_label = (preds[i, j] >= 0.5).long()\n",
    "\n",
    "            correct_total += (pred_label == gt[i]).item()\n",
    "            total += 1\n",
    "\n",
    "    rand_acc = correct_total / max(1, total)\n",
    "\n",
    "    stats = {\n",
    "        \"total_samples\": total,\n",
    "        \"samples_with_valid_tool\": samples_with_valid,\n",
    "        \"fraction_with_valid_tool\": samples_with_valid / max(1, total),\n",
    "    }\n",
    "\n",
    "    return rand_acc, stats\n",
    "\n",
    "\n",
    "for task_idx in range(num_tasks):\n",
    "    rand_acc, stats = compute_random_router_accuracy(\n",
    "        val_loader,\n",
    "        task_idx=task_idx,\n",
    "        device=device,\n",
    "    )\n",
    "    print(f\"Random router accuracy (task {task_idx}): {rand_acc:.4f}\")\n",
    "    print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93735fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = imports.DySTANceLoss_v2(\n",
    "    surrogate_type=\"logistic\",\n",
    "    lambda_entropy=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7281e639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 34/34 [05:28<00:00,  9.66s/it]\n",
      "Validation: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] Train Loss: -143.3824 | Val Regret: 0.0158 | Val Acc: 0.3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 34/34 [05:31<00:00,  9.74s/it]\n",
      "Validation: 100%|██████████| 11/11 [00:11<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] Train Loss: -147.4650 | Val Regret: 0.0148 | Val Acc: 0.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 34/34 [05:38<00:00,  9.95s/it]\n",
      "Validation: 100%|██████████| 11/11 [00:11<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02] Train Loss: -143.4751 | Val Regret: 0.0045 | Val Acc: 0.3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 34/34 [05:38<00:00,  9.95s/it]\n",
      "Validation: 100%|██████████| 11/11 [00:10<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03] Train Loss: -143.5812 | Val Regret: 0.0028 | Val Acc: 0.3089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 3/34 [00:32<05:31, 10.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m num_epochs = \u001b[32m100\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     train_loss = \u001b[43mtrain_one_epoch_all_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     val_metrics = evaluate_all_tasks(model, val_loader, ctx_mgr)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     11\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Regret: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_metrics[\u001b[33m'\u001b[39m\u001b[33mavg_regret\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVal Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_metrics[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mtrain_one_epoch_all_tasks\u001b[39m\u001b[34m(model, loader, ctx_mgr, optimizer, criterion, task_weights)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 2) Build context tensors for this task\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m#    (build_context_tensors must return CPU tensors; move to device)\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m ctx_img_feat, ctx_gt, ctx_pred = \u001b[43mbuild_context_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Ensure returned tensors are moved to the correct device\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# (some implementations already return on device; this is idempotent)\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx_img_feat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mbuild_context_tensors\u001b[39m\u001b[34m(ctx_mgr, task_idx, device)\u001b[39m\n\u001b[32m     33\u001b[39m C = ctx_mgr.examples_per_tool \u001b[38;5;66;03m# number of examples\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tool_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     ctx = \u001b[43mctx_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;66;03m# No valid context for this tool-task pair\u001b[39;00m\n\u001b[32m     40\u001b[39m         ctx_img_feats.append(\n\u001b[32m     41\u001b[39m             torch.zeros(C, model.img_dim, device=device)\n\u001b[32m     42\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/DySTANce/dev_notebooks/imports.py:307\u001b[39m, in \u001b[36mContextManager.sample_context\u001b[39m\u001b[34m(self, tool_idx, task_idx)\u001b[39m\n\u001b[32m    305\u001b[39m imgs, gt, preds = [], [], []\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    309\u001b[39m     \u001b[38;5;66;03m# Each context triple corresponds to:\u001b[39;00m\n\u001b[32m    310\u001b[39m     \u001b[38;5;66;03m#   image x_b\u001b[39;00m\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m#   ground-truth label y_b^t\u001b[39;00m\n\u001b[32m    312\u001b[39m     \u001b[38;5;66;03m#   tool prediction m_E^t(x_b)\u001b[39;00m\n\u001b[32m    313\u001b[39m     imgs.append(item[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/DySTANce/dev_notebooks/imports.py:153\u001b[39m, in \u001b[36mOpenIRoutedDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m    151\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m.records[idx]\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m    155\u001b[39m         img = \u001b[38;5;28mself\u001b[39m.transform(img)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/eal2d-t/lib/python3.12/site-packages/PIL/Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3462\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch_all_tasks(\n",
    "        model, train_loader, ctx_mgr, optimizer, criterion\n",
    "    )\n",
    "\n",
    "    val_metrics = evaluate_all_tasks(model, val_loader, ctx_mgr)\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:02d}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Regret: {val_metrics['avg_regret']:.4f} | \"\n",
    "        f\"Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f9c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router eval: 100%|██████████| 17/17 [00:00<00:00, 93.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75, 'num_samples': 264}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_random_router_accuracy(\n",
    "    loader,\n",
    "    num_tasks,\n",
    "    device=\"cpu\",\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes random-router accuracy, directly comparable to DySTANce Val Acc.\n",
    "\n",
    "    For each batch:\n",
    "      - sample a task\n",
    "      - randomly select a valid tool\n",
    "      - check binary correctness\n",
    "\n",
    "    Returns:\n",
    "        dict with accuracy and sample count\n",
    "    \"\"\"\n",
    "    rng = torch.Generator(device=device)\n",
    "    rng.manual_seed(seed)\n",
    "\n",
    "    correct_total = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Random router eval\"):\n",
    "        gt_all = batch[\"gt\"].to(device)              # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)     # [B, M, L]\n",
    "\n",
    "        B = gt_all.size(0)\n",
    "\n",
    "        task_idx = torch.randint(\n",
    "            0, num_tasks, (1,), generator=rng, device=device\n",
    "        ).item()\n",
    "\n",
    "        gt = gt_all[:, task_idx]                     # [B]\n",
    "        preds = preds_all[:, :, task_idx]            # [B, M]\n",
    "        mask = mask_all[:, :, task_idx]              # [B, M]\n",
    "\n",
    "        for i in range(B):\n",
    "            valid_tools = torch.nonzero(mask[i], as_tuple=False).squeeze(-1)\n",
    "\n",
    "            if valid_tools.numel() == 0:\n",
    "                total_samples += 1\n",
    "                continue\n",
    "\n",
    "            j = valid_tools[\n",
    "                torch.randint(\n",
    "                    0, valid_tools.numel(), (1,),\n",
    "                    generator=rng, device=device\n",
    "                ).item()\n",
    "            ]\n",
    "\n",
    "            pred_label = (preds[i, j] >= 0.5).long()\n",
    "            correct_total += (pred_label == gt[i]).item()\n",
    "            total_samples += 1\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_total / max(1, total_samples),\n",
    "        \"num_samples\": total_samples,\n",
    "    }\n",
    "\n",
    "res = evaluate_random_router_accuracy(\n",
    "    val_loader,\n",
    "    num_tasks=num_tasks,\n",
    "    device=device,\n",
    "    seed=0,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aaac76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upper ceiling eval: 100%|██████████| 17/17 [00:00<00:00, 97.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9621212121212122, 'num_samples': 264}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_upper_ceiling_accuracy(\n",
    "    loader,\n",
    "    num_tasks,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the upper-ceiling accuracy:\n",
    "    sample is correct if ANY valid tool predicts correctly.\n",
    "\n",
    "    Directly comparable to DySTANce Val Acc.\n",
    "    \"\"\"\n",
    "\n",
    "    correct_total = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Upper ceiling eval\"):\n",
    "        gt_all = batch[\"gt\"].to(device)              # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)     # [B, M, L]\n",
    "\n",
    "        B = gt_all.size(0)\n",
    "\n",
    "        # same protocol: random task per batch\n",
    "        task_idx = torch.randint(0, num_tasks, (1,), device=device).item()\n",
    "\n",
    "        gt = gt_all[:, task_idx]                     # [B]\n",
    "        preds = preds_all[:, :, task_idx]            # [B, M]\n",
    "        mask = mask_all[:, :, task_idx]              # [B, M]\n",
    "\n",
    "        pred_labels = (preds >= 0.5).long()          # [B, M]\n",
    "        gt_exp = gt.unsqueeze(1).expand_as(pred_labels)\n",
    "\n",
    "        correct = (pred_labels == gt_exp) & mask.bool()\n",
    "\n",
    "        correct_total += correct.any(dim=1).sum().item()\n",
    "        total_samples += B\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_total / max(1, total_samples),\n",
    "        \"num_samples\": total_samples,\n",
    "    }\n",
    "\n",
    "res = evaluate_upper_ceiling_accuracy(\n",
    "    val_loader,\n",
    "    num_tasks=num_tasks,\n",
    "    device=device,\n",
    ")\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "121b07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_single_tool_accuracy(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    tool_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Accuracy of a fixed tool for a given task.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        gt = batch[\"gt\"][:, task_idx].to(device)               # [B]\n",
    "        preds = batch[\"tool_preds\"][:, tool_idx, task_idx].to(device)\n",
    "        mask = batch[\"tool_mask\"][:, tool_idx, task_idx].to(device)\n",
    "\n",
    "        # Only count samples where the tool is valid\n",
    "        valid = mask.bool()\n",
    "        if valid.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pred_labels = (preds[valid] >= 0.5).long()\n",
    "        correct += (pred_labels == gt[valid]).sum().item()\n",
    "        total += valid.sum().item()\n",
    "\n",
    "    return correct / max(1, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ba28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_single_tool_oracle(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Chooses the best tool based on validation performance itself.\n",
    "    Oracle baseline.\n",
    "    \"\"\"\n",
    "    M = dataloader.dataset.M\n",
    "    accs = []\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        acc = evaluate_single_tool_accuracy(\n",
    "            dataloader, task_idx, tool_idx, device\n",
    "        )\n",
    "        accs.append(acc)\n",
    "\n",
    "    best_acc = max(accs)\n",
    "    best_tool = accs.index(best_acc)\n",
    "\n",
    "    return {\n",
    "        \"best_accuracy\": best_acc,\n",
    "        \"best_tool_idx\": best_tool,\n",
    "        \"all_tool_accuracies\": accs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7194dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_single_tool_on_train(\n",
    "    train_loader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Selects the best tool using TRAIN data only.\n",
    "    \"\"\"\n",
    "    M = train_loader.dataset.dataset.M\n",
    "    accs = []\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        acc = evaluate_single_tool_accuracy(\n",
    "            train_loader, task_idx, tool_idx, device\n",
    "        )\n",
    "        accs.append(acc)\n",
    "\n",
    "    best_tool = accs.index(max(accs))\n",
    "    return best_tool, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7213b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_single_tool_train_selected(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train-selected fixed-tool baseline.\n",
    "    \"\"\"\n",
    "    best_tool, train_accs = select_best_single_tool_on_train(\n",
    "        train_loader, task_idx, device\n",
    "    )\n",
    "\n",
    "    val_acc = evaluate_single_tool_accuracy(\n",
    "        val_loader, task_idx, best_tool, device\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"selected_tool\": best_tool,\n",
    "        \"train_acc\": train_accs[best_tool],\n",
    "        \"val_acc\": val_acc,\n",
    "        \"all_train_accs\": train_accs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d292be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle best single tool:\n",
      "  Val Acc: 1.0000\n",
      "  Tool idx: 8\n",
      "\n",
      "Train-selected best single tool:\n",
      "  Train Acc: 0.9929\n",
      "  Val Acc: 0.9924\n",
      "  Tool idx: 7\n"
     ]
    }
   ],
   "source": [
    "task_idx = 2  # Pneumonia\n",
    "\n",
    "oracle = evaluate_best_single_tool_oracle(\n",
    "    val_loader, task_idx, device\n",
    ")\n",
    "\n",
    "train_sel = evaluate_best_single_tool_train_selected(\n",
    "    train_loader, val_loader, task_idx, device\n",
    ")\n",
    "\n",
    "print(\"Oracle best single tool:\")\n",
    "print(f\"  Val Acc: {oracle['best_accuracy']:.4f}\")\n",
    "print(f\"  Tool idx: {oracle['best_tool_idx']}\")\n",
    "\n",
    "print(\"\\nTrain-selected best single tool:\")\n",
    "print(f\"  Train Acc: {train_sel['train_acc']:.4f}\")\n",
    "print(f\"  Val Acc: {train_sel['val_acc']:.4f}\")\n",
    "print(f\"  Tool idx: {train_sel['selected_tool']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e272ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eal2d-t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

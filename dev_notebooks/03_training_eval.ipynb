{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e2c90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Get repository root directory\n",
    "# Try multiple methods to find the repo root\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'data').exists():\n",
    "    REPO_ROOT = cwd\n",
    "elif (cwd.parent / 'data').exists():\n",
    "    REPO_ROOT = cwd.parent\n",
    "else:\n",
    "    # Fallback: assume we're in dev_notebooks and go up one level\n",
    "    REPO_ROOT = cwd.parent\n",
    "\n",
    "import imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdcb9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic expet settings:\n",
    "\n",
    "# 1. Train on all tools, test on all tools\n",
    "# 2. Train on some tools, test on rest of tools\n",
    "# 3. Mixture of tools seen/unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73f1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Paths\n",
    "# ------------------------------------------------------------\n",
    "DATA_ROOT = REPO_ROOT / \"data\" / \"openi\"\n",
    "LABELS_DIR = DATA_ROOT / \"labels\"\n",
    "IMAGES_DIR = DATA_ROOT / \"image\"\n",
    "PRED_DIR   = DATA_ROOT / \"predictions\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Labels (tasks)\n",
    "# ------------------------------------------------------------\n",
    "label_names = [\n",
    "    \"Atelectasis\", \"Consolidation\", \"Infiltration\", \"Pneumothorax\",\n",
    "    \"Edema\", \"Emphysema\", \"Fibrosis\", \"Effusion\", \"Pneumonia\",\n",
    "    \"Pleural_Thickening\", \"Cardiomegaly\", \"Nodule\", \"Mass\", \"Hernia\",\n",
    "    \"Lung Lesion\", \"Fracture\", \"Lung Opacity\", \"Enlarged Cardiomediastinum\"\n",
    "]\n",
    "num_tasks = len(label_names)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Tool registry\n",
    "# ------------------------------------------------------------\n",
    "registry_all = imports.scan_prediction_files(str(PRED_DIR))\n",
    "\n",
    "# Example split: train on non-resnet tools\n",
    "train_tools = [t for t in registry_all[\"train\"]]\n",
    "\n",
    "train_registry = {t: registry_all[\"train\"][t] for t in train_tools}\n",
    "val_registry   = {t: registry_all[\"val\"][t]   for t in train_tools}\n",
    "test_registry  = {t: registry_all[\"test\"][t]  for t in train_tools}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Datasets\n",
    "# ------------------------------------------------------------\n",
    "train_dataset_full = imports.OpenIRoutedDataset(\n",
    "    label_csv=str(LABELS_DIR / \"Train.csv\"),\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    predictions_registry=train_registry,\n",
    "    label_names=label_names,\n",
    "    transform=None,  # assume tensor conversion inside dataset\n",
    ")\n",
    "\n",
    "val_dataset = imports.OpenIRoutedDataset(\n",
    "    label_csv=str(LABELS_DIR / \"Valid.csv\"),\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    predictions_registry=val_registry,\n",
    "    label_names=label_names,\n",
    "    transform=None,\n",
    ")\n",
    "\n",
    "te_dataset = imports.OpenIRoutedDataset(\n",
    "    label_csv=str(LABELS_DIR / \"Test.csv\"),\n",
    "    images_dir=str(IMAGES_DIR),\n",
    "    predictions_registry=test_registry,\n",
    "    label_names=label_names,\n",
    "    transform=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9c643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_mgr = imports.ContextManager(\n",
    "    dataset=train_dataset_full,\n",
    "    context_fraction=0.1,      # 10% context\n",
    "    examples_per_tool=32,      # B_t\n",
    ")\n",
    "\n",
    "train_dataset = ctx_mgr.routing_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b777e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    te_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcde5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = imports.DySTANceRouter(\n",
    "    num_tasks=num_tasks,\n",
    "    vocab_size=1000,   # dummy vocab size for now\n",
    "    hidden_dim=256,\n",
    ").to(device)\n",
    "\n",
    "# criterion = imports.DySTANceLoss(\n",
    "#     surrogate_type=\"logistic\",\n",
    "#     lambda_entropy=0.05,\n",
    "# )\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-5,,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "\n",
    "def build_context_tensors(ctx_mgr, task_idx, model, device):\n",
    "    \"\"\"\n",
    "    Builds task-conditional context tensors for all tools.\n",
    "\n",
    "    Returns:\n",
    "        ctx_img_feat : [M, C, Dx] on `device`\n",
    "        ctx_gt       : [M, C]     on `device`\n",
    "        ctx_pred     : [M, C]     on `device`\n",
    "    \"\"\"\n",
    "    ctx_img_feats = []\n",
    "    ctx_gts = []\n",
    "    ctx_preds = []\n",
    "\n",
    "    M = ctx_mgr.dataset.M # number of tools\n",
    "    C = ctx_mgr.examples_per_tool # number of examples\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        ctx = ctx_mgr.sample_context(tool_idx, task_idx)\n",
    "\n",
    "        if ctx is None:\n",
    "            # No valid context for this tool-task pair\n",
    "            ctx_img_feats.append(\n",
    "                torch.zeros(C, model.img_dim, device=device)\n",
    "            )\n",
    "            ctx_gts.append(\n",
    "                torch.zeros(C, device=device)\n",
    "            )\n",
    "            ctx_preds.append(\n",
    "                torch.zeros(C, device=device)\n",
    "            )\n",
    "        else:\n",
    "            imgs, gt, preds = ctx\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            gt = gt.to(device)\n",
    "            preds = preds.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                feats = model.extract_img_feat(imgs)  # [C, Dx]\n",
    "\n",
    "            ctx_img_feats.append(feats)\n",
    "            ctx_gts.append(gt)\n",
    "            ctx_preds.append(preds)\n",
    "\n",
    "    return (\n",
    "        torch.stack(ctx_img_feats, dim=0),  # [M, C, Dx]\n",
    "        torch.stack(ctx_gts, dim=0),        # [M, C]\n",
    "        torch.stack(ctx_preds, dim=0),      # [M, C]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b2c15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_one_epoch(model, loader, ctx_mgr, optimizer, criterion):\n",
    "#     model.train()\n",
    "\n",
    "#     total_loss = 0.0\n",
    "#     total_batches = 0\n",
    "\n",
    "#     for batch in tqdm(loader, desc=\"Training\"):\n",
    "#         images = batch[\"image\"].to(device)        # [B, 3, H, W]\n",
    "#         gt_all = batch[\"gt\"].to(device)           # [B, L]\n",
    "#         preds_all = batch[\"tool_preds\"].to(device)  # [B, M, L]\n",
    "#         mask_all = batch[\"tool_mask\"].to(device)    # [B, M, L]\n",
    "\n",
    "#         B = images.size(0)\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # 1) Sample a task uniformly\n",
    "#         # ------------------------------------------------------------\n",
    "#         task_idx = random.randint(0, num_tasks - 1)\n",
    "#         task_ids = torch.full((B,), task_idx, device=device, dtype=torch.long)\n",
    "\n",
    "#         # Task-conditional slices\n",
    "#         gt = gt_all[:, task_idx]                 # [B]\n",
    "#         tool_preds = preds_all[:, :, task_idx]   # [B, M]\n",
    "#         tool_mask  = mask_all[:, :, task_idx]    # [B, M]\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # 2) Build context for this task\n",
    "#         # ------------------------------------------------------------\n",
    "#         ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(\n",
    "#             ctx_mgr, task_idx, device\n",
    "#         )\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # 3) Forward pass\n",
    "#         # ------------------------------------------------------------\n",
    "#         scores = model(\n",
    "#             images=images,\n",
    "#             text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text\n",
    "#             task_idx=task_ids,\n",
    "#             tool_preds=tool_preds,\n",
    "#             ctx_img_feat=ctx_img_feat,\n",
    "#             ctx_gt=ctx_gt,\n",
    "#             ctx_pred=ctx_pred,\n",
    "#             tool_mask=tool_mask,\n",
    "#         )\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # 4) Compute costs (classification task)\n",
    "#         # c_E = 1 - confidence on true label\n",
    "#         # ------------------------------------------------------------\n",
    "#         tool_costs = 1.0 - tool_preds  # [B, M]\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # 5) Loss + backward\n",
    "#         # ------------------------------------------------------------\n",
    "#         loss, logs = criterion(scores, tool_costs, tool_mask)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "#         total_batches += 1\n",
    "\n",
    "#     return total_loss / max(1, total_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56bf52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# helper for empty context\n",
    "def _empty_context(M, model, device):\n",
    "    Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "    return (\n",
    "        torch.zeros((M, 0, Dx), device=device),\n",
    "        torch.zeros((M, 0), device=device),\n",
    "        torch.zeros((M, 0), device=device),\n",
    "    )\n",
    "\n",
    "def train_one_epoch_all_tasks(\n",
    "    model,\n",
    "    loader,\n",
    "    ctx_mgr,\n",
    "    optimizer,\n",
    "    criterion,  # expects (router_logits, tool_probs, gt, validity_mask) -> (loss, info)\n",
    "    num_tasks: int,\n",
    "    device: torch.device,\n",
    "    task_weights: Optional[torch.Tensor] = None,\n",
    "    resample_per_batch: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train one epoch: compute routing loss for EVERY task per batch, average across tasks,\n",
    "    one optimizer step per batch.\n",
    "\n",
    "    Assumptions:\n",
    "      - batch[\"tool_preds\"][:, :, t] is P(y=1) for each tool on task t (binary)\n",
    "      - batch[\"gt\"][:, t] in {0,1}\n",
    "      - criterion implements Eq.(7)-style comp-sum surrogate consistently with those semantics\n",
    "\n",
    "    Features:\n",
    "      - Context tensors are cached per task within an epoch for efficiency and rebuilt each epoch to prevent cross-epoch leakage.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Task weights\n",
    "    if task_weights is None:\n",
    "        task_weights = torch.ones((num_tasks,), dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        task_weights = task_weights.to(device).float()\n",
    "\n",
    "    # Cache contexts per task (huge speedup). If resample_per_batch=True we\n",
    "    # will ignore this cache and rebuild contexts each batch.\n",
    "    ctx_cache = {}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        images    = batch[\"image\"].to(device)       # [B,3,H,W]\n",
    "        gt_all    = batch[\"gt\"].to(device)          # [B,T]\n",
    "        probs_all = batch[\"tool_preds\"].to(device)  # [B,M,T]  (P(y=1))\n",
    "        mask_all  = batch[\"tool_mask\"].to(device)   # [B,M,T]  (0/1)\n",
    "\n",
    "        B = images.size(0)\n",
    "        M = probs_all.size(1)\n",
    "\n",
    "        loss_sum_tasks = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for t in range(num_tasks):\n",
    "            # Task slices\n",
    "            gt        = gt_all[:, t]           # [B]\n",
    "            tool_probs = probs_all[:, :, t]    # [B,M]\n",
    "            tool_mask  = mask_all[:, :, t]     # [B,M]\n",
    "\n",
    "            # Keep only samples with at least one valid tool\n",
    "            valid_counts = tool_mask.sum(dim=1)          # [B] -- in this batch, how many tools are valid?\n",
    "            valid_samples = valid_counts > 0             # [B] bool -- are there any valid tools in this batch?\n",
    "            if valid_samples.sum().item() == 0:          # skip if no valid tools in batch\n",
    "                continue\n",
    "\n",
    "            idxs = torch.nonzero(valid_samples, as_tuple=False).squeeze(1)\n",
    "            images_v = images[idxs]\n",
    "            gt_v = gt[idxs]\n",
    "            tool_probs_v = tool_probs[idxs]\n",
    "            tool_mask_v  = tool_mask[idxs]\n",
    "            Bv = idxs.numel()\n",
    "\n",
    "            # === CONTEXT EMBEDDING: reuse epoch cache OR resample per batch (streamlined) ===\n",
    "            use_cache = (not resample_per_batch) and (t in ctx_cache)\n",
    "            if use_cache:\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = ctx_cache[t]\n",
    "            else:\n",
    "                # build (either because we are resampling each batch, or first time this epoch)\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, model, device=device)\n",
    "\n",
    "                # normalize missing context to zero-shaped placeholders\n",
    "                if ctx_img_feat is None:\n",
    "                    ctx_img_feat, ctx_gt, ctx_pred = _empty_context(M, model, device)\n",
    "                else:\n",
    "                    # make sure everything is on the right device (idempotent)\n",
    "                    ctx_img_feat = ctx_img_feat.to(device)\n",
    "                    ctx_gt = ctx_gt.to(device)\n",
    "                    ctx_pred = ctx_pred.to(device)\n",
    "\n",
    "                # only store in epoch cache when using epoch-caching mode\n",
    "                if not resample_per_batch:\n",
    "                    ctx_cache[t] = (ctx_img_feat, ctx_gt, ctx_pred)\n",
    "\n",
    "\n",
    "            # Forward (router logits over tools)\n",
    "            task_ids = torch.full((Bv,), t, device=device, dtype=torch.long)\n",
    "            router_logits = model(\n",
    "                images=images_v,\n",
    "                text_tokens=torch.zeros((Bv, 1), dtype=torch.long, device=device),\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_probs_v,   # pass tool probs if model uses them as features\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask_v,\n",
    "            )  # [Bv, M]\n",
    "\n",
    "            # Compute loss (NO manual tool_costs here)\n",
    "            loss_t, logs = criterion(\n",
    "                router_logits=router_logits,\n",
    "                tool_probs=tool_probs_v,\n",
    "                gt=gt_v,\n",
    "                validity_mask=tool_mask_v,\n",
    "            )\n",
    "\n",
    "            w_t = task_weights[t]\n",
    "            loss_sum_tasks = loss_sum_tasks + (w_t * loss_t)\n",
    "            weight_sum = weight_sum + w_t\n",
    "\n",
    "        if weight_sum.item() == 0:\n",
    "            continue\n",
    "\n",
    "        loss_batch = loss_sum_tasks / weight_sum\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss_batch.detach().cpu().item())\n",
    "        total_batches += 1\n",
    "\n",
    "    return total_loss / max(1, total_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f400aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def evaluate(model, loader, ctx_mgr):\n",
    "#     \"\"\"\n",
    "#     Evaluates DySTANce router on:\n",
    "#       - average regret\n",
    "#       - per-task accuracy (binary)\n",
    "\n",
    "#     Task is sampled per batch (same as training).\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "\n",
    "#     total_regret = 0.0\n",
    "#     total_samples = 0\n",
    "#     correct_total = 0\n",
    "\n",
    "#     for batch in tqdm(loader, desc=\"Validation\"):\n",
    "#         images = batch[\"image\"].to(device)\n",
    "#         gt_all = batch[\"gt\"].to(device)                # [B, L]\n",
    "#         preds_all = batch[\"tool_preds\"].to(device)     # [B, M, L]\n",
    "#         mask_all = batch[\"tool_mask\"].to(device)       # [B, M, L]\n",
    "\n",
    "#         B = images.size(0)\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Sample a task (same protocol as training)\n",
    "#         # ------------------------------------------------------------\n",
    "#         task_idx = random.randint(0, num_tasks - 1)\n",
    "#         task_ids = torch.full((B,), task_idx, device=device, dtype=torch.long)\n",
    "\n",
    "#         gt = gt_all[:, task_idx]                       # [B]\n",
    "#         tool_preds = preds_all[:, :, task_idx]         # [B, M]\n",
    "#         tool_mask  = mask_all[:, :, task_idx]          # [B, M]\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Build task-conditional context\n",
    "#         # ------------------------------------------------------------\n",
    "#         ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(\n",
    "#             ctx_mgr, task_idx, device\n",
    "#         )\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Forward pass\n",
    "#         # ------------------------------------------------------------\n",
    "#         scores = model(\n",
    "#             images,\n",
    "#             torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text\n",
    "#             task_ids,\n",
    "#             tool_preds,\n",
    "#             ctx_img_feat,\n",
    "#             ctx_gt,\n",
    "#             ctx_pred,\n",
    "#             tool_mask,\n",
    "#         )\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Routing decision\n",
    "#         # ------------------------------------------------------------\n",
    "#         chosen = scores.argmax(dim=1)  # [B]\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Regret computation\n",
    "#         # ------------------------------------------------------------\n",
    "#         costs = 1.0 - tool_preds       # [B, M]\n",
    "\n",
    "#         chosen_cost = costs[torch.arange(B), chosen]\n",
    "#         oracle_cost = costs.masked_fill(tool_mask == 0, 1e9).min(dim=1).values\n",
    "\n",
    "#         total_regret += (chosen_cost - oracle_cost).sum().item()\n",
    "\n",
    "#         # ------------------------------------------------------------\n",
    "#         # Accuracy computation (binary)\n",
    "#         # ------------------------------------------------------------\n",
    "#         chosen_preds = tool_preds[torch.arange(B), chosen]  # [B]\n",
    "#         chosen_labels = (chosen_preds >= 0.5).long()\n",
    "\n",
    "#         correct_total += (chosen_labels == gt).sum().item()\n",
    "#         total_samples += B\n",
    "\n",
    "#     avg_regret = total_regret / max(1, total_samples)\n",
    "#     accuracy = correct_total / max(1, total_samples)\n",
    "\n",
    "#     return {\n",
    "#         \"avg_regret\": avg_regret,\n",
    "#         \"accuracy\": accuracy,\n",
    "#         \"num_samples\": total_samples,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002f7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def evaluate_all_tasks(model, loader, ctx_mgr):\n",
    "#     \"\"\"\n",
    "#     Evaluate DySTANce over EVERY task per batch (no random single-task sampling).\n",
    "\n",
    "#     Returns a dict with:\n",
    "#       - avg_regret      : average regret across all considered (sample,task) pairs\n",
    "#       - accuracy        : overall accuracy (router chosen tool vs GT)\n",
    "#       - per_task_acc    : list of per-task accuracies\n",
    "#       - random_acc      : random-router baseline accuracy\n",
    "#       - upper_bound_acc : oracle upper-ceiling accuracy\n",
    "#       - num_pairs       : number of considered (sample,task) pairs\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "\n",
    "#     # Accumulators\n",
    "#     total_regret = 0.0\n",
    "#     total_correct = 0\n",
    "#     total_pairs = 0\n",
    "\n",
    "#     # Per-task accumulators\n",
    "#     per_task_correct = [0 for _ in range(num_tasks)]\n",
    "#     per_task_pairs = [0 for _ in range(num_tasks)]\n",
    "\n",
    "#     # Baselines\n",
    "#     random_correct = 0\n",
    "#     upper_correct = 0\n",
    "\n",
    "#     # Cache contexts per task to avoid repeated builds\n",
    "#     ctx_cache = {}\n",
    "\n",
    "#     for batch in tqdm(loader, desc=\"Validation\"):\n",
    "#         images = batch[\"image\"].to(device)            # [B, C, H, W]\n",
    "#         gt_all  = batch[\"gt\"].to(device)             # [B, L]\n",
    "#         preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "#         mask_all  = batch[\"tool_mask\"].to(device)    # [B, M, L]\n",
    "\n",
    "#         B = images.shape[0]\n",
    "\n",
    "#         # For each task, evaluate all samples in batch (but skip samples with no valid tool)\n",
    "#         for t in range(num_tasks):\n",
    "#             # Task slices\n",
    "#             gt = gt_all[:, t]                       # [B]\n",
    "#             tool_preds = preds_all[:, :, t]         # [B, M]\n",
    "#             tool_mask  = mask_all[:, :, t]          # [B, M] {0,1}\n",
    "\n",
    "#             # Determine which samples in this batch have at least one valid tool\n",
    "#             valid_tool_counts = tool_mask.sum(dim=1)        # [B]\n",
    "#             valid_samples_mask = (valid_tool_counts > 0)   # [B] bool\n",
    "\n",
    "#             if valid_samples_mask.sum().item() == 0:\n",
    "#                 # no sample in this batch has any valid tool for this task -> skip\n",
    "#                 continue\n",
    "\n",
    "#             # Build / fetch cached context for task t (move to device)\n",
    "#             if t in ctx_cache:\n",
    "#                 ctx_img_feat, ctx_gt, ctx_pred = ctx_cache[t]\n",
    "#             else:\n",
    "#                 ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, device=device)\n",
    "#                 # move to device (build_context_tensors may return CPU tensors)\n",
    "#                 if ctx_img_feat is not None:\n",
    "#                     ctx_img_feat = ctx_img_feat.to(device)\n",
    "#                     ctx_gt = ctx_gt.to(device)\n",
    "#                     ctx_pred = ctx_pred.to(device)\n",
    "#                 else:\n",
    "#                     # Create zero-sized contexts if none exist (ANP should handle B_t=0)\n",
    "#                     M = preds_all.shape[1]\n",
    "#                     Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "#                     ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "#                     ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "#                     ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "\n",
    "#                 ctx_cache[t] = (ctx_img_feat, ctx_gt, ctx_pred)\n",
    "\n",
    "#             # Build task ids for the batch\n",
    "#             task_ids = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "\n",
    "#             # Forward pass (model expected to handle masking internally)\n",
    "#             scores = model(\n",
    "#                 images=images,\n",
    "#                 text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),  # dummy text (or real tokens if available)\n",
    "#                 task_idx=task_ids,\n",
    "#                 tool_preds=tool_preds,\n",
    "#                 ctx_img_feat=ctx_img_feat,\n",
    "#                 ctx_gt=ctx_gt,\n",
    "#                 ctx_pred=ctx_pred,\n",
    "#                 tool_mask=tool_mask,\n",
    "#             )  # [B, M]\n",
    "\n",
    "#             # Ensure invalid tools have very low score (safety)\n",
    "#             scores = scores.masked_fill(tool_mask == 0, -1e9)\n",
    "\n",
    "#             # Choose best tool per sample\n",
    "#             chosen = scores.argmax(dim=1)  # [B] (may point to invalid tool if all -inf; but we filtered such samples)\n",
    "\n",
    "#             # Consider only samples with at least one valid tool\n",
    "#             idxs = torch.nonzero(valid_samples_mask, as_tuple=False).squeeze(1)  # [B_valid]\n",
    "#             if idxs.numel() == 0:\n",
    "#                 continue\n",
    "\n",
    "#             # Subset arrays to valid samples\n",
    "#             chosen_v = chosen[idxs]                          # [B_valid]\n",
    "#             gt_v = gt[idxs]                                 # [B_valid]\n",
    "#             preds_v = tool_preds[idxs]                      # [B_valid, M]\n",
    "#             mask_v  = tool_mask[idxs]                       # [B_valid, M]\n",
    "\n",
    "#             # Costs: c = 1 - confidence (soft proxy)\n",
    "#             costs_v = 1.0 - preds_v                         # [B_valid, M]\n",
    "\n",
    "#             # Chosen cost and oracle cost\n",
    "#             chosen_cost = costs_v[torch.arange(idxs.numel(), device=device), chosen_v]  # [B_valid]\n",
    "\n",
    "#             # Oracle: min cost among valid tools\n",
    "#             inf_mask = (~(mask_v.bool())).float() * 1e9\n",
    "#             costs_for_oracle = costs_v + inf_mask\n",
    "#             oracle_cost = costs_for_oracle.min(dim=1).values  # [B_valid]\n",
    "\n",
    "#             total_regret += (chosen_cost - oracle_cost).sum().item()\n",
    "\n",
    "#             # Accuracy: interpret chosen tool's prediction as binary label (>=0.5)\n",
    "#             chosen_pred_probs = preds_v[torch.arange(idxs.numel(), device=device), chosen_v]  # [B_valid]\n",
    "#             chosen_labels = (chosen_pred_probs >= 0.5).long()\n",
    "#             correct = (chosen_labels == gt_v).sum().item()\n",
    "#             total_correct += int(correct)\n",
    "#             total_pairs += int(idxs.numel())\n",
    "\n",
    "#             # Per-task accounting\n",
    "#             per_task_correct[t] += int(correct)\n",
    "#             per_task_pairs[t] += int(idxs.numel())\n",
    "\n",
    "#             # --- Baselines for these valid samples --------------------------------\n",
    "#             # Random-router baseline: choose uniformly among valid tools for each sample\n",
    "#             # We implement this in vectorized-ish manner:\n",
    "#             Bv, M = preds_v.shape\n",
    "#             # Create list of valid tool indices per sample\n",
    "#             # We'll loop here across Bv (Bv is smallish per batch)\n",
    "#             for i in range(Bv):\n",
    "#                 valid_indices = torch.nonzero(mask_v[i].bool(), as_tuple=False).squeeze(1)\n",
    "#                 if valid_indices.numel() == 0:\n",
    "#                     # Shouldn't happen due to earlier filtering\n",
    "#                     continue\n",
    "#                 # Random pick\n",
    "#                 rnd_idx = int(valid_indices[torch.randint(0, valid_indices.numel(), (1,)).item()].item())\n",
    "#                 rnd_prob = preds_v[i, rnd_idx].item()\n",
    "#                 rnd_label = 1 if rnd_prob >= 0.5 else 0\n",
    "#                 if rnd_label == int(gt_v[i].item()):\n",
    "#                     random_correct += 1\n",
    "\n",
    "#                 # Upper-ceiling: any valid tool predicts correctly?\n",
    "#                 # If any valid tool's binary prediction equals gt, count as correct\n",
    "#                 # (treat prob>=0.5 as predicting label=1)\n",
    "#                 valid_probs = preds_v[i, valid_indices]\n",
    "#                 valid_preds_bin = (valid_probs >= 0.5).long()\n",
    "#                 if (valid_preds_bin == int(gt_v[i].item())).any():\n",
    "#                     upper_correct += 1\n",
    "#             # ----------------------------------------------------------------------\n",
    "\n",
    "#     # After all batches\n",
    "#     avg_regret = total_regret / max(1, total_pairs)\n",
    "#     accuracy = total_correct / max(1, total_pairs)\n",
    "#     per_task_acc = [ (per_task_correct[t] / per_task_pairs[t]) if per_task_pairs[t] > 0 else None\n",
    "#                      for t in range(num_tasks) ]\n",
    "\n",
    "#     random_acc = random_correct / max(1, total_pairs)\n",
    "#     upper_acc  = upper_correct / max(1, total_pairs)\n",
    "\n",
    "#     return {\n",
    "#         \"avg_regret\": avg_regret,\n",
    "#         \"accuracy\": accuracy,\n",
    "#         \"per_task_acc\": per_task_acc,\n",
    "#         \"random_acc\": random_acc,\n",
    "#         \"upper_acc\": upper_acc,\n",
    "#         \"num_pairs\": total_pairs,\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07811cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def compute_upper_ceiling_accuracy(\n",
    "#     dataloader,\n",
    "#     task_idx: int,\n",
    "#     device=\"cpu\",\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Computes the upper-ceiling accuracy for a single task.\n",
    "\n",
    "#     Upper-ceiling = fraction of samples for which at least one\n",
    "#     valid tool predicts the correct label.\n",
    "\n",
    "#     Args:\n",
    "#         dataloader : DataLoader yielding OpenIRoutedDataset batches\n",
    "#         task_idx   : int, which task (label) to evaluate\n",
    "#         device     : torch device\n",
    "\n",
    "#     Returns:\n",
    "#         ceiling_acc : float in [0,1]\n",
    "#         stats       : dict with additional diagnostics\n",
    "#     \"\"\"\n",
    "#     total = 0\n",
    "#     count_ceiling = 0\n",
    "#     count_any_valid = 0\n",
    "\n",
    "#     for batch in tqdm(dataloader, desc=f\"Ceiling task {task_idx}\"):\n",
    "#         gt = batch[\"gt\"][:, task_idx].to(device)            # [B]\n",
    "#         preds = batch[\"tool_preds\"][:, :, task_idx].to(device)  # [B, M]\n",
    "#         mask = batch[\"tool_mask\"][:, :, task_idx].to(device)    # [B, M]\n",
    "\n",
    "#         B, M = preds.shape\n",
    "\n",
    "#         # Predicted labels per tool (binary classification)\n",
    "#         pred_labels = (preds >= 0.5).long()  # [B, M]\n",
    "\n",
    "#         # Ground truth expanded\n",
    "#         gt_exp = gt.unsqueeze(1).expand(-1, M)  # [B, M]\n",
    "\n",
    "#         # Correct predictions per tool\n",
    "#         correct = (pred_labels == gt_exp) & (mask.bool())  # [B, M]\n",
    "\n",
    "#         # For each sample: does ANY tool get it right?\n",
    "#         any_correct = correct.any(dim=1)  # [B]\n",
    "\n",
    "#         # For sanity: does sample have ANY valid tool?\n",
    "#         any_valid = mask.any(dim=1)       # [B]\n",
    "\n",
    "#         count_ceiling += any_correct.sum().item()\n",
    "#         count_any_valid += any_valid.sum().item()\n",
    "#         total += B\n",
    "\n",
    "#     ceiling_acc = count_ceiling / max(1, total)\n",
    "\n",
    "#     stats = {\n",
    "#         \"total_samples\": total,\n",
    "#         \"samples_with_any_valid_tool\": count_any_valid,\n",
    "#         \"fraction_with_any_valid_tool\": count_any_valid / max(1, total),\n",
    "#     }\n",
    "\n",
    "#     return ceiling_acc, stats\n",
    "\n",
    "# for task_idx in range(num_tasks):\n",
    "#     ceiling_acc, stats = compute_upper_ceiling_accuracy(\n",
    "#         val_loader,\n",
    "#         task_idx=task_idx,\n",
    "#         device=device,\n",
    "#     )\n",
    "\n",
    "#     print(f\"Upper-ceiling accuracy (task {task_idx}): {ceiling_acc:.4f}\")\n",
    "#     print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31a26392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def compute_random_router_accuracy(\n",
    "#     dataloader,\n",
    "#     task_idx: int,\n",
    "#     device=\"cpu\",\n",
    "#     seed: int = 0,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Computes accuracy of a random router for a single task.\n",
    "\n",
    "#     For each sample:\n",
    "#       - uniformly sample one VALID tool\n",
    "#       - use its prediction as the output\n",
    "\n",
    "#     Args:\n",
    "#         dataloader : DataLoader yielding OpenIRoutedDataset batches\n",
    "#         task_idx   : int, which task (label) to evaluate\n",
    "#         device     : torch device\n",
    "#         seed       : random seed for reproducibility\n",
    "\n",
    "#     Returns:\n",
    "#         rand_acc : float in [0,1]\n",
    "#         stats    : dict\n",
    "#     \"\"\"\n",
    "#     rng = torch.Generator(device=device)\n",
    "#     rng.manual_seed(seed)\n",
    "\n",
    "#     total = 0\n",
    "#     correct_total = 0\n",
    "#     samples_with_valid = 0\n",
    "\n",
    "#     for batch in tqdm(dataloader, desc=f\"Random router task {task_idx}\"):\n",
    "#         gt = batch[\"gt\"][:, task_idx].to(device)             # [B]\n",
    "#         preds = batch[\"tool_preds\"][:, :, task_idx].to(device)  # [B, M]\n",
    "#         mask = batch[\"tool_mask\"][:, :, task_idx].to(device)    # [B, M]\n",
    "\n",
    "#         B, M = preds.shape\n",
    "\n",
    "#         for i in range(B):\n",
    "#             valid_tools = torch.nonzero(mask[i], as_tuple=False).squeeze(-1)\n",
    "\n",
    "#             if valid_tools.numel() == 0:\n",
    "#                 # No valid tool: cannot predict (count as incorrect)\n",
    "#                 total += 1\n",
    "#                 continue\n",
    "\n",
    "#             samples_with_valid += 1\n",
    "\n",
    "#             # Uniform random choice among valid tools\n",
    "#             j = valid_tools[\n",
    "#                 torch.randint(\n",
    "#                     low=0,\n",
    "#                     high=valid_tools.numel(),\n",
    "#                     size=(1,),\n",
    "#                     generator=rng,\n",
    "#                     device=device,\n",
    "#                 ).item()\n",
    "#             ]\n",
    "\n",
    "#             # Binary prediction\n",
    "#             pred_label = (preds[i, j] >= 0.5).long()\n",
    "\n",
    "#             correct_total += (pred_label == gt[i]).item()\n",
    "#             total += 1\n",
    "\n",
    "#     rand_acc = correct_total / max(1, total)\n",
    "\n",
    "#     stats = {\n",
    "#         \"total_samples\": total,\n",
    "#         \"samples_with_valid_tool\": samples_with_valid,\n",
    "#         \"fraction_with_valid_tool\": samples_with_valid / max(1, total),\n",
    "#     }\n",
    "\n",
    "#     return rand_acc, stats\n",
    "\n",
    "\n",
    "# for task_idx in range(num_tasks):\n",
    "#     rand_acc, stats = compute_random_router_accuracy(\n",
    "#         val_loader,\n",
    "#         task_idx=task_idx,\n",
    "#         device=device,\n",
    "#     )\n",
    "#     print(f\"Random router accuracy (task {task_idx}): {rand_acc:.4f}\")\n",
    "#     print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93735fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = imports.DySTANceCompSumEq7Loss(\n",
    "    surrogate_type=\"logistic\",\n",
    "    lambda_entropy=0.00,\n",
    "    cost_centering=\"none\",          # or \"min\" if you want your workaround\n",
    "    clamp_negative_weights=False,   # optionally True for stability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52b02bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from imports import costs_from_probs_binary\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_all_tasks(model, loader, ctx_mgr, num_tasks: int, device: torch.device):\n",
    "    \"\"\"\n",
    "    Evaluate routing via argmax over router scores.\n",
    "\n",
    "    Assumptions:\n",
    "      - tool_preds[b, m, t] is P(y=1) for tool m on task t\n",
    "      - gt_all[b, t] in {0,1}\n",
    "      - tool_mask[b, m, t] in {0,1}\n",
    "\n",
    "    Returns:\n",
    "      - avg_regret : mean(chosen_cost - oracle_cost) using label-aware expected 0-1 costs\n",
    "      - accuracy   : fraction where chosen tool’s thresholded label matches gt\n",
    "      - per_task_acc, random_acc, upper_acc, num_pairs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_regret = 0.0\n",
    "    total_correct = 0\n",
    "    total_pairs = 0\n",
    "\n",
    "    per_task_correct = [0 for _ in range(num_tasks)]\n",
    "    per_task_pairs = [0 for _ in range(num_tasks)]\n",
    "\n",
    "    random_correct = 0\n",
    "    upper_correct = 0\n",
    "\n",
    "    ctx_cache = {}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Validation\"):\n",
    "        images = batch[\"image\"].to(device)            # [B,C,H,W]\n",
    "        gt_all = batch[\"gt\"].to(device)               # [B,T]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)    # [B,M,T] = P(y=1)\n",
    "        mask_all = batch[\"tool_mask\"].to(device)      # [B,M,T] in {0,1}\n",
    "\n",
    "        B = images.shape[0]\n",
    "        M = preds_all.shape[1]\n",
    "\n",
    "        for t in range(num_tasks):\n",
    "            gt = gt_all[:, t]                         # [B]\n",
    "            tool_probs = preds_all[:, :, t]           # [B,M]\n",
    "            tool_mask = mask_all[:, :, t]             # [B,M]\n",
    "\n",
    "            valid_counts = tool_mask.sum(dim=1)       # [B]\n",
    "            valid_samples = valid_counts > 0          # [B] bool\n",
    "            if valid_samples.sum().item() == 0:\n",
    "                continue\n",
    "\n",
    "            # Context cache\n",
    "            if t in ctx_cache:\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = ctx_cache[t]\n",
    "            else:\n",
    "                ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, model, device=device)\n",
    "                if ctx_img_feat is not None:\n",
    "                    ctx_img_feat = ctx_img_feat.to(device)\n",
    "                    ctx_gt = ctx_gt.to(device)\n",
    "                    ctx_pred = ctx_pred.to(device)\n",
    "                else:\n",
    "                    Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "                    ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "                    ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "                    ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "                ctx_cache[t] = (ctx_img_feat, ctx_gt, ctx_pred)\n",
    "\n",
    "            task_ids = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "\n",
    "            scores = model(\n",
    "                images=images,\n",
    "                text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_probs,\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask,\n",
    "            )  # [B,M]\n",
    "\n",
    "            # Mask invalid tools\n",
    "            scores = scores.masked_fill(tool_mask == 0, -1e9)\n",
    "\n",
    "            # Argmax tool choice\n",
    "            chosen = scores.argmax(dim=1)  # [B]\n",
    "\n",
    "            # Keep only samples with at least one valid tool\n",
    "            idxs = torch.nonzero(valid_samples, as_tuple=False).squeeze(1)\n",
    "            if idxs.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            chosen_v = chosen[idxs]           # [Bv]\n",
    "            gt_v = gt[idxs]                   # [Bv]\n",
    "            probs_v = tool_probs[idxs]        # [Bv,M]\n",
    "            mask_v = tool_mask[idxs]          # [Bv,M]\n",
    "            Bv = idxs.numel()\n",
    "\n",
    "            # --------- Regret/oracle costs (label-aware, in [0,1]) ----------\n",
    "            costs_v = costs_from_probs_binary(probs_v, gt_v)          # [Bv,M]\n",
    "            costs_v = costs_v.masked_fill(mask_v == 0, 1e9)           # invalid -> huge\n",
    "\n",
    "            chosen_cost = costs_v[torch.arange(Bv, device=device), chosen_v]  # [Bv]\n",
    "            oracle_cost = costs_v.min(dim=1).values                              # [Bv]\n",
    "\n",
    "            total_regret += (chosen_cost - oracle_cost).sum().item()\n",
    "\n",
    "            # --------- Accuracy (thresholded label of chosen tool) ----------\n",
    "            chosen_probs = probs_v[torch.arange(Bv, device=device), chosen_v]   # [Bv]\n",
    "            chosen_labels = (chosen_probs >= 0.5).long()\n",
    "            correct = (chosen_labels == gt_v).sum().item()\n",
    "\n",
    "            total_correct += int(correct)\n",
    "            total_pairs += int(Bv)\n",
    "            per_task_correct[t] += int(correct)\n",
    "            per_task_pairs[t] += int(Bv)\n",
    "\n",
    "            # --------- Random baseline (uniform among valid tools) ----------\n",
    "            # multinomial over the {0,1} mask gives uniform among valid entries\n",
    "            sampled = torch.multinomial(mask_v.float(), num_samples=1).squeeze(1)  # [Bv]\n",
    "            rnd_probs = probs_v[torch.arange(Bv, device=device), sampled]\n",
    "            rnd_labels = (rnd_probs >= 0.5).long()\n",
    "            random_correct += int((rnd_labels == gt_v).sum().item())\n",
    "\n",
    "            # --------- Upper bound accuracy: any valid tool predicts correctly ----------\n",
    "            preds_bin = (probs_v >= 0.5).long()                     # [Bv,M]\n",
    "            gt_expand = gt_v.unsqueeze(1).expand_as(preds_bin)      # [Bv,M]\n",
    "            any_correct = ((preds_bin == gt_expand) & (mask_v.bool())).any(dim=1)\n",
    "            upper_correct += int(any_correct.sum().item())\n",
    "\n",
    "    avg_regret = total_regret / max(1, total_pairs)\n",
    "    accuracy = total_correct / max(1, total_pairs)\n",
    "    per_task_acc = [\n",
    "        (per_task_correct[t] / per_task_pairs[t]) if per_task_pairs[t] > 0 else None\n",
    "        for t in range(num_tasks)\n",
    "    ]\n",
    "    random_acc = random_correct / max(1, total_pairs)\n",
    "    upper_acc = upper_correct / max(1, total_pairs)\n",
    "\n",
    "    return {\n",
    "        \"avg_regret\": avg_regret,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"per_task_acc\": per_task_acc,\n",
    "        \"random_acc\": random_acc,\n",
    "        \"upper_acc\": upper_acc,\n",
    "        \"num_pairs\": total_pairs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4f602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = train_loader\n",
    "# task_weights = None\n",
    "# resample_per_batch = False\n",
    "# ########################################################\n",
    "# model.train()\n",
    "# total_loss = 0.0\n",
    "# total_batches = 0\n",
    "\n",
    "# # Task weights\n",
    "# if task_weights is None:\n",
    "#     task_weights = torch.ones((num_tasks,), dtype=torch.float32, device=device) # [T]\n",
    "# else:\n",
    "#     task_weights = task_weights.to(device).float()\n",
    "\n",
    "# # Cache contexts per task (huge speedup)\n",
    "# ctx_cache = {}\n",
    "\n",
    "# for batch in tqdm(loader, desc=\"Training\"):\n",
    "#     images    = batch[\"image\"].to(device)       # [B,3,H,W]\n",
    "#     gt_all    = batch[\"gt\"].to(device)          # [B,T]\n",
    "#     probs_all = batch[\"tool_preds\"].to(device)  # [B,M,T]  (P(y=1))\n",
    "#     mask_all  = batch[\"tool_mask\"].to(device)   # [B,M,T]  (0/1)\n",
    "\n",
    "#     B = images.size(0)\n",
    "#     M = probs_all.size(1)\n",
    "\n",
    "#     loss_sum_tasks = 0.0\n",
    "#     weight_sum = 0.0\n",
    "\n",
    "#     for t in range(num_tasks): # loop over all tasks\n",
    "#         # get Task slices\n",
    "#         gt        = gt_all[:, t]           # [B]\n",
    "#         tool_probs = probs_all[:, :, t]    # [B,M] -- some will be 0.5 (invalid)\n",
    "#         tool_mask  = mask_all[:, :, t]     # [B,M]\n",
    "\n",
    "#         # Keep only samples with at least one valid tool\n",
    "#         valid_counts = tool_mask.sum(dim=1)          # [B] -- in this batch, how many tools are valid?\n",
    "#         valid_samples = valid_counts > 0             # [B] bool -- are there any valid tools in this batch?\n",
    "#         if valid_samples.sum().item() == 0:          # skip if no valid tools in batch\n",
    "#             continue\n",
    "\n",
    "#         # get valid samples from batch \n",
    "#         idxs = torch.nonzero(valid_samples, as_tuple=False).squeeze(1) # [Bv] -- get indices of samples with valid tools\n",
    "#         images_v = images[idxs]\n",
    "#         gt_v = gt[idxs]\n",
    "#         tool_probs_v = tool_probs[idxs]\n",
    "#         tool_mask_v  = tool_mask[idxs]\n",
    "#         Bv = idxs.numel()\n",
    "\n",
    "#         # === CONTEXT: reuse epoch cache OR resample per batch (streamlined) ===\n",
    "#         use_cache = (not resample_per_batch) and (t in ctx_cache)\n",
    "#         if use_cache:\n",
    "#             ctx_img_feat, ctx_gt, ctx_pred = ctx_cache[t]\n",
    "#         else:\n",
    "#             # build (either because we are resampling each batch, or first time this epoch)\n",
    "#             ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, model, device=device)\n",
    "\n",
    "#             # normalize missing context to zero-shaped placeholders\n",
    "#             if ctx_img_feat is None:\n",
    "#                 ctx_img_feat, ctx_gt, ctx_pred = _empty_context(M, model, device)\n",
    "#             else:\n",
    "#                 # make sure everything is on the right device (idempotent)\n",
    "#                 ctx_img_feat = ctx_img_feat.to(device)\n",
    "#                 ctx_gt = ctx_gt.to(device)\n",
    "#                 ctx_pred = ctx_pred.to(device)\n",
    "\n",
    "#             # only store in epoch cache when using epoch-caching mode\n",
    "#             if not resample_per_batch:\n",
    "#                 ctx_cache[t] = (ctx_img_feat, ctx_gt, ctx_pred)\n",
    "\n",
    "\n",
    "#         # Forward (router logits over tools)\n",
    "#         task_ids = torch.full((Bv,), t, device=device, dtype=torch.long) \n",
    "#         router_logits = model(\n",
    "#             images=images_v,\n",
    "#             text_tokens=torch.zeros((Bv, 1), dtype=torch.long, device=device),\n",
    "#             task_idx=task_ids,\n",
    "#             tool_preds=tool_probs_v,   # pass tool probs if model uses them as features\n",
    "#             ctx_img_feat=ctx_img_feat,\n",
    "#             ctx_gt=ctx_gt,\n",
    "#             ctx_pred=ctx_pred,\n",
    "#             tool_mask=tool_mask_v,\n",
    "#         )  # [Bv, M]\n",
    "#         break\n",
    "\n",
    "#         # Compute loss (NO manual tool_costs here)\n",
    "#         loss_t, logs = criterion(\n",
    "#             router_logits=router_logits,\n",
    "#             tool_probs=tool_probs_v,\n",
    "#             gt=gt_v,\n",
    "#             validity_mask=tool_mask_v,\n",
    "#         )\n",
    "\n",
    "#         w_t = task_weights[t]\n",
    "#         loss_sum_tasks = loss_sum_tasks + (w_t * loss_t)\n",
    "#         weight_sum = weight_sum + w_t\n",
    "#     break\n",
    "\n",
    "#     # if weight_sum.item() == 0:\n",
    "#     #     continue\n",
    "\n",
    "#     # loss_batch = loss_sum_tasks / weight_sum\n",
    "\n",
    "#     # optimizer.zero_grad(set_to_none=True)\n",
    "#     # loss_batch.backward()\n",
    "#     # optimizer.step()\n",
    "\n",
    "#     # total_loss += float(loss_batch.detach().cpu().item())\n",
    "#     # total_batches += 1\n",
    "\n",
    "# # fin = total_loss / max(1, total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51609cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps = 1e-8\n",
    "# import torch.nn.functional as F\n",
    "# ### loss dev\n",
    "\n",
    "# B, M = router_logits.shape\n",
    "# device = router_logits.device\n",
    "\n",
    "# validity_mask = tool_mask_v.to(device)\n",
    "# tool_probs = tool_probs_v.to(device)\n",
    "# gt = gt_v.to(device)\n",
    "\n",
    "# # ------------\n",
    "# # 1) Masked softmax -> pi over valid tools\n",
    "# # ------------\n",
    "# very_neg = -1e9\n",
    "# masked_logits = router_logits.masked_fill(validity_mask == 0, very_neg) # --- e^-very_neg = 0\n",
    "# pi = F.softmax(masked_logits, dim=1)                 # [B,M] -- softmax over the tool logits\n",
    "# pi = pi * validity_mask                              # zero invalid\n",
    "# pi = pi / (pi.sum(dim=1, keepdim=True) + eps)   # renormalize -- make sure sum to 1 after masking\n",
    "\n",
    "# # Effective panel size\n",
    "# m_eff = validity_mask.sum(dim=1, keepdim=True)       # [B,1] -- sum over valid tools. Asks how many tools are valid for each sample.\n",
    "# m_eff_clamped = torch.clamp(m_eff, min=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825399af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost_centering = \"none\"\n",
    "# # ------------\n",
    "# # 2) Compute costs in [0,1] from tool_probs and gt\n",
    "# #    c = y*(1-p) + (1-y)*p\n",
    "# # ------------\n",
    "# gt_f = gt.float().unsqueeze(1)                       # [B,1]\n",
    "# tool_costs = gt_f * (1.0 - tool_probs) + (1.0 - gt_f) * tool_probs  # [B,M]\n",
    "# tool_costs = tool_costs * validity_mask              # invalid -> 0 (masked anyway)\n",
    "\n",
    "# # Optional per-sample min-centering (heuristic; changes the surrogate)\n",
    "# if cost_centering == \"min\":\n",
    "#     big = 1e9\n",
    "#     costs_for_min = tool_costs + (1.0 - validity_mask) * big\n",
    "#     min_cost, _ = costs_for_min.min(dim=1, keepdim=True)\n",
    "#     min_cost = torch.where(min_cost > big / 2.0, torch.zeros_like(min_cost), min_cost)\n",
    "#     tool_costs = (tool_costs - min_cost).clamp_min(0.0)  # keep >=0 for valid\n",
    "# else:\n",
    "#     min_cost = torch.zeros((B,1), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712bf545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clamp_negative_weights = False\n",
    "# # ------------\n",
    "# # 3) Comp-sum weights (variable panel size version)\n",
    "# #    w_j = sum_{k != j} c_k - m_eff + 2\n",
    "# # ------------\n",
    "# sum_costs = tool_costs.sum(dim=1, keepdim=True)       # [B,1]\n",
    "# w = (sum_costs - tool_costs) - m_eff_clamped + 2.0    # [B,M]\n",
    "# w = w * validity_mask\n",
    "\n",
    "# # Optional stabilizer: prevent negative weights (not faithful to Eq.7)\n",
    "# if clamp_negative_weights:\n",
    "#     w = torch.clamp(w, min=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281e639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:56<00:00,  5.60s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 00] val_regret improved -> 0.069494 (saved best model)\n",
      "[Epoch 00] Train Loss: -315.8013 | Val Regret: 0.0695 | Val Acc: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [05:00<00:00,  5.67s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] val_regret improved -> 0.063770 (saved best model)\n",
      "[Epoch 01] Train Loss: -835.6876 | Val Regret: 0.0638 | Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [05:00<00:00,  5.67s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02] val_regret improved -> 0.061070 (saved best model)\n",
      "[Epoch 02] Train Loss: -962.0937 | Val Regret: 0.0611 | Val Acc: 0.9104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:59<00:00,  5.65s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03] no improvement (val_regret 0.065450), patience 1/25\n",
      "[Epoch 03] Train Loss: -606.0123 | Val Regret: 0.0654 | Val Acc: 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:57<00:00,  5.62s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 04] no improvement (val_regret 0.066341), patience 2/25\n",
      "[Epoch 04] Train Loss: -314.8905 | Val Regret: 0.0663 | Val Acc: 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:56<00:00,  5.59s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 05] val_regret improved -> 0.058023 (saved best model)\n",
      "[Epoch 05] Train Loss: -327.2323 | Val Regret: 0.0580 | Val Acc: 0.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:55<00:00,  5.58s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 06] no improvement (val_regret 0.064881), patience 1/25\n",
      "[Epoch 06] Train Loss: -811.3403 | Val Regret: 0.0649 | Val Acc: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:59<00:00,  5.65s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 07] no improvement (val_regret 0.068046), patience 2/25\n",
      "[Epoch 07] Train Loss: -1117.5113 | Val Regret: 0.0680 | Val Acc: 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:54<00:00,  5.56s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 08] val_regret improved -> 0.056754 (saved best model)\n",
      "[Epoch 08] Train Loss: -1451.2742 | Val Regret: 0.0568 | Val Acc: 0.9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:58<00:00,  5.63s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 09] no improvement (val_regret 0.075552), patience 1/25\n",
      "[Epoch 09] Train Loss: -1667.3506 | Val Regret: 0.0756 | Val Acc: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:51<00:00,  5.50s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] no improvement (val_regret 0.077764), patience 2/25\n",
      "[Epoch 10] Train Loss: -1415.1578 | Val Regret: 0.0778 | Val Acc: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:55<00:00,  5.58s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] no improvement (val_regret 0.059901), patience 3/25\n",
      "[Epoch 11] Train Loss: -1691.2141 | Val Regret: 0.0599 | Val Acc: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:53<00:00,  5.54s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] no improvement (val_regret 0.067156), patience 4/25\n",
      "[Epoch 12] Train Loss: -1807.3988 | Val Regret: 0.0672 | Val Acc: 0.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:56<00:00,  5.60s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] no improvement (val_regret 0.079558), patience 5/25\n",
      "[Epoch 13] Train Loss: -1754.7618 | Val Regret: 0.0796 | Val Acc: 0.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [05:00<00:00,  5.67s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] no improvement (val_regret 0.087507), patience 6/25\n",
      "[Epoch 14] Train Loss: -1829.2562 | Val Regret: 0.0875 | Val Acc: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 53/53 [04:55<00:00,  5.57s/it]\n",
      "Validation: 100%|██████████| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] no improvement (val_regret 0.064986), patience 7/25\n",
      "[Epoch 15] Train Loss: -1848.0772 | Val Regret: 0.0650 | Val Acc: 0.9057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 36/53 [03:21<01:35,  5.63s/it]"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# --- early stopping / training loop params ---\n",
    "num_epochs = 100\n",
    "patience = 25            # number of epochs with no improvement to wait\n",
    "min_delta = 1e-4        # minimum improvement in val_regret to count as improvement\n",
    "verbose = True\n",
    "\n",
    "# optional: use a scheduler that supports step(metric) like ReduceLROnPlateau\n",
    "use_scheduler = False\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "best_val_regret = float(\"inf\")\n",
    "best_epoch = -1\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch_all_tasks(\n",
    "        model,\n",
    "        train_loader,\n",
    "        ctx_mgr,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        num_tasks=18,\n",
    "        device=device,\n",
    "        resample_per_batch=True,\n",
    "    )\n",
    "\n",
    "    val_metrics = evaluate_all_tasks(model, val_loader, ctx_mgr, num_tasks=18, device=device)\n",
    "    val_regret = float(val_metrics[\"avg_regret\"])\n",
    "\n",
    "    # # Scheduler (optional): if using ReduceLROnPlateau, notify it of validation metric\n",
    "    # if use_scheduler:\n",
    "    #     scheduler.step(val_regret)\n",
    "\n",
    "    improved = (best_val_regret - val_regret) > min_delta\n",
    "\n",
    "    if improved:\n",
    "        best_val_regret = val_regret\n",
    "        best_epoch = epoch\n",
    "        # keep best model state (deepcopy to be safe)\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch:02d}] val_regret improved -> {val_regret:.6f} (saved best model)\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch:02d}] no improvement (val_regret {val_regret:.6f}), \"\n",
    "                  f\"patience {epochs_no_improve}/{patience}\")\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:02d}] Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Regret: {val_regret:.4f} | Val Acc: {val_metrics['accuracy']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Early stopping check\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered (no improvement in {patience} epochs).\")\n",
    "        break\n",
    "\n",
    "# Restore best weights (if any)\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"Restored best model from epoch {best_epoch} with val_regret={best_val_regret:.6f}\")\n",
    "else:\n",
    "    print(\"No improvement seen during training; final model kept as-is.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# re-use helper from earlier fix\n",
    "def costs_from_probs_binary(preds: torch.Tensor, gt: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    preds: [B, M] probabilities P(y=1)\n",
    "    gt:    [B] binary {0,1}\n",
    "    returns costs [B, M] in [0,1] = expected 0-1 error w.r.t. gt\n",
    "    \"\"\"\n",
    "    gt_f = gt.float().unsqueeze(1)  # [B,1]\n",
    "    return gt_f * (1.0 - preds) + (1.0 - gt_f) * preds\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_router_choices(model, test_loader, ctx_mgr, num_tasks, device, max_examples_per_tool=5):\n",
    "    \"\"\"\n",
    "    Runs evaluation and returns diagnostics about which tool is chosen and how it performs.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - per_task_tool_counts[t][m] = count of times tool m was chosen for task t\n",
    "      - per_task_tool_correct[t][m] = number of correct predictions when tool m was chosen\n",
    "      - per_task_tool_regret_sum[t][m] = sum of regret when tool m was chosen\n",
    "      - per_task_total_pairs[t] = total valid (sample,task) pairs considered\n",
    "      - overall_df: pandas DataFrame with one row per valid (sample,task):\n",
    "            columns: ['global_idx','task','chosen_tool','chosen_prob','chosen_label','gt',\n",
    "                      'chosen_cost','oracle_tool','oracle_cost','regret','mask_valid_tools']\n",
    "      - examples_by_tool[(t,m)] = list of example dicts (up to max_examples_per_tool) for quick inspection\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # accumulators\n",
    "    per_task_tool_counts = [defaultdict(int) for _ in range(num_tasks)]\n",
    "    per_task_tool_correct = [defaultdict(int) for _ in range(num_tasks)]\n",
    "    per_task_tool_regret_sum = [defaultdict(float) for _ in range(num_tasks)]\n",
    "    per_task_total_pairs = [0 for _ in range(num_tasks)]\n",
    "\n",
    "    rows = []  # to build DataFrame of per-(sample,task) rows\n",
    "    examples_by_tool = defaultdict(list)  # key = (task, tool) -> list of examples\n",
    "\n",
    "    global_idx_base = 0  # optional index to identify sample across batches\n",
    "\n",
    "    for batch in tqdm(test_loader, desc=\"Inspecting router\"):\n",
    "        images = batch[\"image\"].to(device)            # [B,C,H,W]\n",
    "        gt_all = batch[\"gt\"].to(device)               # [B,T]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)    # [B,M,T] = P(y=1)\n",
    "        mask_all = batch[\"tool_mask\"].to(device)      # [B,M,T]\n",
    "\n",
    "        B = images.shape[0]\n",
    "        M = preds_all.shape[1]\n",
    "\n",
    "        # iterate tasks (same as eval)\n",
    "        for t in range(num_tasks):\n",
    "            gt = gt_all[:, t]                       # [B]\n",
    "            tool_probs = preds_all[:, :, t]         # [B, M]\n",
    "            tool_mask  = mask_all[:, :, t]          # [B, M]\n",
    "\n",
    "            # skip if no valid tool for any sample in batch\n",
    "            valid_counts = tool_mask.sum(dim=1)     # [B]\n",
    "            valid_samples_mask = (valid_counts > 0) # [B] bool\n",
    "            if valid_samples_mask.sum().item() == 0:\n",
    "                continue\n",
    "\n",
    "            # build context (cache if you already do)\n",
    "            ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, device=device, model=model)\n",
    "            if ctx_img_feat is not None:\n",
    "                ctx_img_feat = ctx_img_feat.to(device)\n",
    "                ctx_gt = ctx_gt.to(device)\n",
    "                ctx_pred = ctx_pred.to(device)\n",
    "            else:\n",
    "                Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "                ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "                ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "                ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "\n",
    "            # forward in one shot for full batch (model should handle masking)\n",
    "            task_ids = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "            scores = model(\n",
    "                images=images,\n",
    "                text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_probs,\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask,\n",
    "            )  # [B, M]\n",
    "\n",
    "            # mask invalid\n",
    "            scores = scores.masked_fill(tool_mask == 0, -1e9)\n",
    "\n",
    "            # chosen tool by argmax\n",
    "            chosen = scores.argmax(dim=1)  # [B]\n",
    "\n",
    "            # Work on valid sample subset\n",
    "            idxs = torch.nonzero(valid_samples_mask, as_tuple=False).squeeze(1)\n",
    "            if idxs.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            chosen_v = chosen[idxs]                     # [Bv]\n",
    "            gt_v = gt[idxs]                             # [Bv]\n",
    "            probs_v = tool_probs[idxs]                  # [Bv, M]\n",
    "            mask_v = tool_mask[idxs]                    # [Bv, M]\n",
    "            Bv = idxs.numel()\n",
    "\n",
    "            # compute costs and oracle\n",
    "            costs_v = costs_from_probs_binary(probs_v, gt_v)   # [Bv,M]\n",
    "            costs_for_oracle = costs_v.masked_fill(mask_v == 0, 1e9)\n",
    "            oracle_costs, oracle_idx = costs_for_oracle.min(dim=1)  # [Bv], [Bv]\n",
    "            chosen_cost = costs_v[torch.arange(Bv, device=device), chosen_v]  # [Bv]\n",
    "\n",
    "            # compute regret\n",
    "            regret = (chosen_cost - oracle_costs)  # [Bv]\n",
    "\n",
    "            # chosen predicted labels and correctness (threshold 0.5)\n",
    "            chosen_probs = probs_v[torch.arange(Bv, device=device), chosen_v]  # [Bv]\n",
    "            chosen_labels = (chosen_probs >= 0.5).long()\n",
    "            correct_mask = (chosen_labels == gt_v).long()\n",
    "\n",
    "            # aggregate per-tool stats for this task\n",
    "            for i in range(Bv):\n",
    "                tool_idx = int(chosen_v[i].item())\n",
    "                per_task_tool_counts[t][tool_idx] += 1\n",
    "                per_task_tool_correct[t][tool_idx] += int(correct_mask[i].item())\n",
    "                per_task_tool_regret_sum[t][tool_idx] += float(regret[i].item())\n",
    "                per_task_total_pairs[t] += 1\n",
    "\n",
    "                # record row for DataFrame (global_idx optional)\n",
    "                row = {\n",
    "                    \"global_idx\": int(global_idx_base + idxs[i].item()),\n",
    "                    \"task\": int(t),\n",
    "                    \"chosen_tool\": tool_idx,\n",
    "                    \"chosen_prob\": float(chosen_probs[i].item()),\n",
    "                    \"chosen_label\": int(chosen_labels[i].item()),\n",
    "                    \"gt\": int(gt_v[i].item()),\n",
    "                    \"chosen_cost\": float(chosen_cost[i].item()),\n",
    "                    \"oracle_tool\": int(oracle_idx[i].item()),\n",
    "                    \"oracle_cost\": float(oracle_costs[i].item()),\n",
    "                    \"regret\": float(regret[i].item()),\n",
    "                    \"valid_tools_mask\": mask_v[i].cpu().numpy().tolist(),\n",
    "                }\n",
    "                rows.append(row)\n",
    "\n",
    "                # Save examples per tool for quick inspection (limit)\n",
    "                key = (t, tool_idx)\n",
    "                if len(examples_by_tool[key]) < max_examples_per_tool:\n",
    "                    examples_by_tool[key].append(row)\n",
    "\n",
    "            global_idx_base += B  # increment by batch size so indices are unique across batches\n",
    "\n",
    "    # Build DataFrame\n",
    "    overall_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Build final per-task per-tool summary (counts, accuracies, avg regrets)\n",
    "    per_task_summary = {}\n",
    "    for t in range(num_tasks):\n",
    "        counts = per_task_tool_counts[t]\n",
    "        corrects = per_task_tool_correct[t]\n",
    "        regrets = per_task_tool_regret_sum[t]\n",
    "        total = per_task_total_pairs[t]\n",
    "        tool_summary = {}\n",
    "        for m in sorted(counts.keys()):\n",
    "            c = counts[m]\n",
    "            corr = corrects.get(m, 0)\n",
    "            reg_sum = regrets.get(m, 0.0)\n",
    "            tool_summary[m] = {\n",
    "                \"count\": c,\n",
    "                \"accuracy\": corr / c if c > 0 else None,\n",
    "                \"avg_regret\": reg_sum / c if c > 0 else None,\n",
    "                \"share\": c / max(1, total),\n",
    "            }\n",
    "        per_task_summary[t] = {\n",
    "            \"total_pairs\": total,\n",
    "            \"tools\": tool_summary\n",
    "        }\n",
    "\n",
    "    diagnostics = {\n",
    "        \"per_task_summary\": per_task_summary,\n",
    "        \"overall_df\": overall_df,\n",
    "        \"examples_by_tool\": examples_by_tool,\n",
    "    }\n",
    "    return diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inspecting router: 100%|██████████| 10/10 [00:57<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 total pairs: 156\n",
      " tool 7: count=16, acc=0.938, avg_regret=0.0410, share=0.103\n",
      " tool 9: count=32, acc=1.000, avg_regret=0.0108, share=0.205\n",
      " tool 12: count=48, acc=0.938, avg_regret=0.0850, share=0.308\n",
      " tool 13: count=16, acc=0.875, avg_regret=0.0524, share=0.103\n",
      " tool 15: count=32, acc=0.906, avg_regret=0.0757, share=0.205\n",
      " tool 17: count=12, acc=1.000, avg_regret=0.0194, share=0.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_idx</th>\n",
       "      <th>task</th>\n",
       "      <th>chosen_tool</th>\n",
       "      <th>chosen_prob</th>\n",
       "      <th>chosen_label</th>\n",
       "      <th>gt</th>\n",
       "      <th>chosen_cost</th>\n",
       "      <th>oracle_tool</th>\n",
       "      <th>oracle_cost</th>\n",
       "      <th>regret</th>\n",
       "      <th>valid_tools_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732694</td>\n",
       "      <td>17</td>\n",
       "      <td>0.021161</td>\n",
       "      <td>0.711532</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424320</td>\n",
       "      <td>8</td>\n",
       "      <td>0.085591</td>\n",
       "      <td>0.338729</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524372</td>\n",
       "      <td>17</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.480218</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527293</td>\n",
       "      <td>14</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.426792</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826650</td>\n",
       "      <td>8</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.798829</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699087</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300913</td>\n",
       "      <td>3</td>\n",
       "      <td>0.290848</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298619</td>\n",
       "      <td>17</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.285292</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790129</td>\n",
       "      <td>17</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.783249</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105902</td>\n",
       "      <td>17</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948971</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948971</td>\n",
       "      <td>17</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.908874</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.479487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479487</td>\n",
       "      <td>14</td>\n",
       "      <td>0.108474</td>\n",
       "      <td>0.371013</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140215</td>\n",
       "      <td>14</td>\n",
       "      <td>0.101466</td>\n",
       "      <td>0.038749</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308795</td>\n",
       "      <td>17</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.288667</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147906</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.144616</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.032681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032681</td>\n",
       "      <td>8</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.021768</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.516599</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073850</td>\n",
       "      <td>0.442749</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>15</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>14</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_idx  task  chosen_tool  chosen_prob  chosen_label  gt  chosen_cost  \\\n",
       "0            0     0            1     0.732694             1   0     0.732694   \n",
       "1            1     0            1     0.424320             0   0     0.424320   \n",
       "2            2     0            1     0.524372             1   0     0.524372   \n",
       "3            3     0            1     0.527293             1   0     0.527293   \n",
       "4            4     0            1     0.826650             1   0     0.826650   \n",
       "5            5     0            1     0.699087             1   1     0.300913   \n",
       "6            6     0            1     0.046845             0   0     0.046845   \n",
       "7            7     0            1     0.298619             0   0     0.298619   \n",
       "8            8     0            1     0.790129             1   0     0.790129   \n",
       "9            9     0            1     0.105902             0   0     0.105902   \n",
       "10          10     0            1     0.948971             1   0     0.948971   \n",
       "11          11     0            1     0.479487             0   0     0.479487   \n",
       "12          12     0            1     0.140215             0   0     0.140215   \n",
       "13          13     0            1     0.308795             0   0     0.308795   \n",
       "14          14     0            1     0.147906             0   0     0.147906   \n",
       "15          15     0            1     0.004743             0   0     0.004743   \n",
       "16          16     1            7     0.032681             0   0     0.032681   \n",
       "17          17     1            7     0.516599             1   0     0.516599   \n",
       "18          18     1            7     0.037329             0   0     0.037329   \n",
       "19          19     1            7     0.013832             0   0     0.013832   \n",
       "\n",
       "    oracle_tool  oracle_cost    regret  \\\n",
       "0            17     0.021161  0.711532   \n",
       "1             8     0.085591  0.338729   \n",
       "2            17     0.044154  0.480218   \n",
       "3            14     0.100500  0.426792   \n",
       "4             8     0.027821  0.798829   \n",
       "5             3     0.290848  0.010065   \n",
       "6             4     0.001795  0.045050   \n",
       "7            17     0.013327  0.285292   \n",
       "8            17     0.006881  0.783249   \n",
       "9            17     0.016726  0.089177   \n",
       "10           17     0.040097  0.908874   \n",
       "11           14     0.108474  0.371013   \n",
       "12           14     0.101466  0.038749   \n",
       "13           17     0.020128  0.288667   \n",
       "14            4     0.003290  0.144616   \n",
       "15            4     0.000003  0.004740   \n",
       "16            8     0.010914  0.021768   \n",
       "17            3     0.073850  0.442749   \n",
       "18           15     0.022073  0.015256   \n",
       "19           14     0.013212  0.000620   \n",
       "\n",
       "                                     valid_tools_mask  \n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "2   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "3   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "5   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "6   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "7   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "8   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "9   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "10  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "11  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "12  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "13  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "14  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "15  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "16  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "17  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "18  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  \n",
       "19  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples where task 0 routed to tool 3:\n",
      "{'global_idx': 576, 'task': 0, 'chosen_tool': 3, 'chosen_prob': 0.30880802869796753, 'chosen_label': 0, 'gt': 0, 'chosen_cost': 0.30880802869796753, 'oracle_tool': 7, 'oracle_cost': 0.009257563389837742, 'regret': 0.29955047369003296, 'valid_tools_mask': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
      "{'global_idx': 577, 'task': 0, 'chosen_tool': 3, 'chosen_prob': 0.11553023010492325, 'chosen_label': 0, 'gt': 0, 'chosen_cost': 0.11553023010492325, 'oracle_tool': 17, 'oracle_cost': 0.011242981068789959, 'regret': 0.10428725183010101, 'valid_tools_mask': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
      "{'global_idx': 578, 'task': 0, 'chosen_tool': 3, 'chosen_prob': 0.24244846403598785, 'chosen_label': 0, 'gt': 0, 'chosen_cost': 0.24244846403598785, 'oracle_tool': 17, 'oracle_cost': 0.04872521758079529, 'regret': 0.19372324645519257, 'valid_tools_mask': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
      "{'global_idx': 579, 'task': 0, 'chosen_tool': 3, 'chosen_prob': 0.019831353798508644, 'chosen_label': 0, 'gt': 0, 'chosen_cost': 0.019831353798508644, 'oracle_tool': 3, 'oracle_cost': 0.019831353798508644, 'regret': 0.0, 'valid_tools_mask': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
      "{'global_idx': 580, 'task': 0, 'chosen_tool': 3, 'chosen_prob': 0.012629842385649681, 'chosen_label': 0, 'gt': 0, 'chosen_cost': 0.012629842385649681, 'oracle_tool': 2, 'oracle_cost': 0.009061580523848534, 'regret': 0.0035682618618011475, 'valid_tools_mask': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "diagnostics = inspect_router_choices(model, test_loader, ctx_mgr, num_tasks, device)\n",
    "\n",
    "# quick print for first task:\n",
    "t = 1\n",
    "print(\"Task\", t, \"total pairs:\", diagnostics[\"per_task_summary\"][t][\"total_pairs\"])\n",
    "for m,info in diagnostics[\"per_task_summary\"][t][\"tools\"].items():\n",
    "    print(f\" tool {m}: count={info['count']}, acc={info['accuracy']:.3f}, avg_regret={info['avg_regret']:.4f}, share={info['share']:.3f}\")\n",
    "\n",
    "# show a few rows\n",
    "display(diagnostics[\"overall_df\"].head(20))\n",
    "\n",
    "# inspect example predictions for a particular (task,tool)\n",
    "print(\"Examples where task 0 routed to tool 3:\")\n",
    "for ex in diagnostics[\"examples_by_tool\"][(0,3)]:\n",
    "    print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeee2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diagnostics['overall_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def routing_dataframe(\n",
    "    model,\n",
    "    loader,\n",
    "    ctx_mgr,\n",
    "    num_tasks: int,\n",
    "    device: torch.device,\n",
    "    image_id_key: str = \"image_id\",  # change if your batch uses a different key\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame with one row per (image, task) routing decision.\n",
    "\n",
    "    Columns:\n",
    "      - image_id\n",
    "      - task\n",
    "      - gt\n",
    "      - chosen_tool\n",
    "      - pred_prob\n",
    "      - pred_label\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    rows = []\n",
    "\n",
    "    global_image_idx = 0  # fallback if no image_id provided\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Building routing dataframe\"):\n",
    "        images = batch[\"image\"].to(device)           # [B,C,H,W]\n",
    "        gt_all = batch[\"gt\"].to(device)              # [B,T]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B,M,T] = P(y=1)\n",
    "        mask_all = batch[\"tool_mask\"].to(device)     # [B,M,T]\n",
    "\n",
    "        # image identifiers\n",
    "        if image_id_key in batch:\n",
    "            image_ids = batch[image_id_key]\n",
    "        else:\n",
    "            B = images.size(0)\n",
    "            image_ids = list(range(global_image_idx, global_image_idx + B))\n",
    "            global_image_idx += B\n",
    "\n",
    "        B, M, _ = preds_all.shape\n",
    "\n",
    "        for t in range(num_tasks):\n",
    "            gt = gt_all[:, t]                 # [B]\n",
    "            tool_probs = preds_all[:, :, t]   # [B,M]\n",
    "            tool_mask  = mask_all[:, :, t]    # [B,M]\n",
    "\n",
    "            # only keep samples with ≥1 valid tool\n",
    "            valid_mask = tool_mask.sum(dim=1) > 0\n",
    "            if valid_mask.sum().item() == 0:\n",
    "                continue\n",
    "\n",
    "            idxs = torch.nonzero(valid_mask, as_tuple=False).squeeze(1)\n",
    "\n",
    "            # context (cached per task if you want)\n",
    "            ctx_img_feat, ctx_gt, ctx_pred = build_context_tensors(ctx_mgr, t, device=device, model=model)\n",
    "            if ctx_img_feat is not None:\n",
    "                ctx_img_feat = ctx_img_feat.to(device)\n",
    "                ctx_gt = ctx_gt.to(device)\n",
    "                ctx_pred = ctx_pred.to(device)\n",
    "            else:\n",
    "                Dx = model.img_dim if hasattr(model, \"img_dim\") else 512\n",
    "                ctx_img_feat = torch.zeros((M, 0, Dx), device=device)\n",
    "                ctx_gt       = torch.zeros((M, 0), device=device)\n",
    "                ctx_pred     = torch.zeros((M, 0), device=device)\n",
    "\n",
    "            # router scores\n",
    "            task_ids = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "            scores = model(\n",
    "                images=images,\n",
    "                text_tokens=torch.zeros((B, 1), dtype=torch.long, device=device),\n",
    "                task_idx=task_ids,\n",
    "                tool_preds=tool_probs,\n",
    "                ctx_img_feat=ctx_img_feat,\n",
    "                ctx_gt=ctx_gt,\n",
    "                ctx_pred=ctx_pred,\n",
    "                tool_mask=tool_mask,\n",
    "            )  # [B,M]\n",
    "\n",
    "            scores = scores.masked_fill(tool_mask == 0, -1e9)\n",
    "            chosen = scores.argmax(dim=1)  # [B]\n",
    "\n",
    "            for i in idxs.tolist():\n",
    "                m = int(chosen[i].item())\n",
    "                p = float(tool_probs[i, m].item())\n",
    "                y = int(gt[i].item())\n",
    "\n",
    "                rows.append({\n",
    "                    \"image_id\": image_ids[i],\n",
    "                    \"task\": int(t),\n",
    "                    \"gt\": y,\n",
    "                    \"chosen_tool\": m,\n",
    "                    \"pred_prob\": p,\n",
    "                    \"pred_label\": int(p >= 0.5),\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c58a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building routing dataframe: 100%|██████████| 10/10 [00:54<00:00,  5.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>task</th>\n",
       "      <th>gt</th>\n",
       "      <th>chosen_tool</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.384786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.389557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.383806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.793852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.262171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  task  gt  chosen_tool  pred_prob  pred_label\n",
       "0         0     0   0           10   0.384786           0\n",
       "1         1     0   0           10   0.389557           0\n",
       "2         2     0   0           10   0.383806           0\n",
       "3         3     0   0           10   0.793852           1\n",
       "4         4     0   0           10   0.262171           0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = routing_dataframe(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    ctx_mgr=ctx_mgr,\n",
    "    num_tasks=num_tasks,\n",
    "    device=device,\n",
    "    image_id_key=\"image_id\",  # or None if you don’t have one\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_label'] = (df['pred_prob'] >= 0.5).astype(int)\n",
    "df['pred_correct'] = (df['pred_label'] == df['gt']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616140bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>task</th>\n",
       "      <th>gt</th>\n",
       "      <th>chosen_tool</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.384786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.505804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.140698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>155</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>155</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>155</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>155</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>155</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2808 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  task  gt  chosen_tool  pred_prob  pred_label\n",
       "0            0     0   0           10   0.384786           0\n",
       "16           0     1   0            4   0.505804           1\n",
       "32           0     2   0           17   0.140698           0\n",
       "48           0     3   0            4   0.538294           1\n",
       "64           0     4   0           14   0.001470           0\n",
       "...        ...   ...  ..          ...        ...         ...\n",
       "2759       155    13   0           15   0.000220           0\n",
       "2771       155    14   0            0   0.079217           0\n",
       "2783       155    15   0            5   0.503880           1\n",
       "2795       155    16   1            1   0.177569           0\n",
       "2807       155    17   1            1   0.138745           0\n",
       "\n",
       "[2808 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['image_id', 'task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada252e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d6f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691d1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random router eval: 100%|██████████| 17/17 [00:00<00:00, 84.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75, 'num_samples': 264}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_random_router_accuracy(\n",
    "    loader,\n",
    "    num_tasks,\n",
    "    device=\"cpu\",\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes random-router accuracy, directly comparable to DySTANce Val Acc.\n",
    "\n",
    "    For each batch:\n",
    "      - sample a task\n",
    "      - randomly select a valid tool\n",
    "      - check binary correctness\n",
    "\n",
    "    Returns:\n",
    "        dict with accuracy and sample count\n",
    "    \"\"\"\n",
    "    rng = torch.Generator(device=device)\n",
    "    rng.manual_seed(seed)\n",
    "\n",
    "    correct_total = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Random router eval\"):\n",
    "        gt_all = batch[\"gt\"].to(device)              # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)     # [B, M, L]\n",
    "\n",
    "        B = gt_all.size(0)\n",
    "\n",
    "        task_idx = torch.randint(\n",
    "            0, num_tasks, (1,), generator=rng, device=device\n",
    "        ).item()\n",
    "\n",
    "        gt = gt_all[:, task_idx]                     # [B]\n",
    "        preds = preds_all[:, :, task_idx]            # [B, M]\n",
    "        mask = mask_all[:, :, task_idx]              # [B, M]\n",
    "\n",
    "        for i in range(B):\n",
    "            valid_tools = torch.nonzero(mask[i], as_tuple=False).squeeze(-1)\n",
    "\n",
    "            if valid_tools.numel() == 0:\n",
    "                total_samples += 1\n",
    "                continue\n",
    "\n",
    "            j = valid_tools[\n",
    "                torch.randint(\n",
    "                    0, valid_tools.numel(), (1,),\n",
    "                    generator=rng, device=device\n",
    "                ).item()\n",
    "            ]\n",
    "\n",
    "            pred_label = (preds[i, j] >= 0.5).long()\n",
    "            correct_total += (pred_label == gt[i]).item()\n",
    "            total_samples += 1\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_total / max(1, total_samples),\n",
    "        \"num_samples\": total_samples,\n",
    "    }\n",
    "\n",
    "res = evaluate_random_router_accuracy(\n",
    "    val_loader,\n",
    "    num_tasks=num_tasks,\n",
    "    device=device,\n",
    "    seed=0,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaac76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upper ceiling eval: 100%|██████████| 17/17 [00:00<00:00, 101.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9734848484848485, 'num_samples': 264}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_upper_ceiling_accuracy(\n",
    "    loader,\n",
    "    num_tasks,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the upper-ceiling accuracy:\n",
    "    sample is correct if ANY valid tool predicts correctly.\n",
    "\n",
    "    Directly comparable to DySTANce Val Acc.\n",
    "    \"\"\"\n",
    "\n",
    "    correct_total = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Upper ceiling eval\"):\n",
    "        gt_all = batch[\"gt\"].to(device)              # [B, L]\n",
    "        preds_all = batch[\"tool_preds\"].to(device)   # [B, M, L]\n",
    "        mask_all = batch[\"tool_mask\"].to(device)     # [B, M, L]\n",
    "\n",
    "        B = gt_all.size(0)\n",
    "\n",
    "        # same protocol: random task per batch\n",
    "        task_idx = torch.randint(0, num_tasks, (1,), device=device).item()\n",
    "\n",
    "        gt = gt_all[:, task_idx]                     # [B]\n",
    "        preds = preds_all[:, :, task_idx]            # [B, M]\n",
    "        mask = mask_all[:, :, task_idx]              # [B, M]\n",
    "\n",
    "        pred_labels = (preds >= 0.5).long()          # [B, M]\n",
    "        gt_exp = gt.unsqueeze(1).expand_as(pred_labels)\n",
    "\n",
    "        correct = (pred_labels == gt_exp) & mask.bool()\n",
    "\n",
    "        correct_total += correct.any(dim=1).sum().item()\n",
    "        total_samples += B\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_total / max(1, total_samples),\n",
    "        \"num_samples\": total_samples,\n",
    "    }\n",
    "\n",
    "res = evaluate_upper_ceiling_accuracy(\n",
    "    val_loader,\n",
    "    num_tasks=num_tasks,\n",
    "    device=device,\n",
    ")\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_single_tool_accuracy(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    tool_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Accuracy of a fixed tool for a given task.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        gt = batch[\"gt\"][:, task_idx].to(device)               # [B]\n",
    "        preds = batch[\"tool_preds\"][:, tool_idx, task_idx].to(device)\n",
    "        mask = batch[\"tool_mask\"][:, tool_idx, task_idx].to(device)\n",
    "\n",
    "        # Only count samples where the tool is valid\n",
    "        valid = mask.bool()\n",
    "        if valid.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        pred_labels = (preds[valid] >= 0.5).long()\n",
    "        correct += (pred_labels == gt[valid]).sum().item()\n",
    "        total += valid.sum().item()\n",
    "\n",
    "    return correct / max(1, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_single_tool_oracle(\n",
    "    dataloader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Chooses the best tool based on validation performance itself.\n",
    "    Oracle baseline.\n",
    "    \"\"\"\n",
    "    M = dataloader.dataset.M\n",
    "    accs = []\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        acc = evaluate_single_tool_accuracy(\n",
    "            dataloader, task_idx, tool_idx, device\n",
    "        )\n",
    "        accs.append(acc)\n",
    "\n",
    "    best_acc = max(accs)\n",
    "    best_tool = accs.index(best_acc)\n",
    "\n",
    "    return {\n",
    "        \"best_accuracy\": best_acc,\n",
    "        \"best_tool_idx\": best_tool,\n",
    "        \"all_tool_accuracies\": accs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_single_tool_on_train(\n",
    "    train_loader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Selects the best tool using TRAIN data only.\n",
    "    \"\"\"\n",
    "    M = train_loader.dataset.dataset.M\n",
    "    accs = []\n",
    "\n",
    "    for tool_idx in range(M):\n",
    "        acc = evaluate_single_tool_accuracy(\n",
    "            train_loader, task_idx, tool_idx, device\n",
    "        )\n",
    "        accs.append(acc)\n",
    "\n",
    "    best_tool = accs.index(max(accs))\n",
    "    return best_tool, accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7213b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_single_tool_train_selected(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    task_idx: int,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train-selected fixed-tool baseline.\n",
    "    \"\"\"\n",
    "    best_tool, train_accs = select_best_single_tool_on_train(\n",
    "        train_loader, task_idx, device\n",
    "    )\n",
    "\n",
    "    val_acc = evaluate_single_tool_accuracy(\n",
    "        val_loader, task_idx, best_tool, device\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"selected_tool\": best_tool,\n",
    "        \"train_acc\": train_accs[best_tool],\n",
    "        \"val_acc\": val_acc,\n",
    "        \"all_train_accs\": train_accs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle best single tool:\n",
      "  Val Acc: 1.0000\n",
      "  Tool idx: 8\n",
      "\n",
      "Train-selected best single tool:\n",
      "  Train Acc: 0.9929\n",
      "  Val Acc: 0.9924\n",
      "  Tool idx: 7\n"
     ]
    }
   ],
   "source": [
    "task_idx = 2  # Pneumonia\n",
    "\n",
    "oracle = evaluate_best_single_tool_oracle(\n",
    "    val_loader, task_idx, device\n",
    ")\n",
    "\n",
    "train_sel = evaluate_best_single_tool_train_selected(\n",
    "    train_loader, val_loader, task_idx, device\n",
    ")\n",
    "\n",
    "print(\"Oracle best single tool:\")\n",
    "print(f\"  Val Acc: {oracle['best_accuracy']:.4f}\")\n",
    "print(f\"  Tool idx: {oracle['best_tool_idx']}\")\n",
    "\n",
    "print(\"\\nTrain-selected best single tool:\")\n",
    "print(f\"  Train Acc: {train_sel['train_acc']:.4f}\")\n",
    "print(f\"  Val Acc: {train_sel['val_acc']:.4f}\")\n",
    "print(f\"  Tool idx: {train_sel['selected_tool']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e272ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eal2d-t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
